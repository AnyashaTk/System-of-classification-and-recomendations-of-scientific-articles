text,space_num,symbolic_percent,space_percent,num_world,num_columns,front_spaces_perc,back_spaces
                                              Astronomy & Astrophysics manuscript no. pera_etal                                                                                 ©ESO 2021,46.0,0.2810810810810811,0.7189189189189189,8.0,41.0,0.24210526315789474,0.02631578947368418
"                                              April 9, 2021",46.0,0.1864406779661017,0.8135593220338984,3.0,1.0,0.24210526315789474,0.6894736842105262
                                                    pyUPMASK: An improved unsupervised clustering algorithm,52.0,0.4672897196261682,0.5327102803738317,6.0,1.0,0.2736842105263158,0.4368421052631579
"                                                                      M. S. Pera1 , G. I. Perren1 , A. Moitinho2 , H. D. Navone3, 4 , and R. A. Vazquez5",70.0,0.4144736842105263,0.5855263157894737,20.0,1.0,0.3684210526315789,0.19999999999999996
                                                    1,52.0,0.018867924528301886,0.9811320754716981,1.0,1.0,0.2736842105263158,0.7210526315789474
"                                                        Instituto de Astrofísica de La Plata (IALP-CONICET), 1900 La Plata, Argentina",56.0,0.5037593984962406,0.49624060150375937,11.0,1.0,0.29473684210526313,0.30000000000000004
                                                        e-mail: msolpera@gmail.com,56.0,0.3048780487804878,0.6951219512195121,2.0,1.0,0.29473684210526313,0.5684210526315789
                                                    2,52.0,0.018867924528301886,0.9811320754716981,1.0,1.0,0.2736842105263158,0.7210526315789474
"                                                        CENTRA, Faculdade de Ciências, Universidade de Lisboa, Ed. C8, Campo Grande, 1749-016 Lisboa, Portugal",56.0,0.5632911392405063,0.43670886075949367,14.0,1.0,0.29473684210526313,0.16842105263157892
                                                    3,52.0,0.018867924528301886,0.9811320754716981,1.0,1.0,0.2736842105263158,0.7210526315789474
"                                                        Facultad de Ciencias Exactas, Ingeniería y Agrimensura (UNR), 2000 Rosario, Argentina",56.0,0.5319148936170213,0.46808510638297873,11.0,1.0,0.29473684210526313,0.2578947368421053
                                                    4,52.0,0.018867924528301886,0.9811320754716981,1.0,1.0,0.2736842105263158,0.7210526315789474
"                                                        Instituto de Física de Rosario (CONICET-UNR), 2000 Rosario, Argentina,",56.0,0.49206349206349204,0.5079365079365079,9.0,1.0,0.29473684210526313,0.33684210526315794
                                                    5,52.0,0.018867924528301886,0.9811320754716981,1.0,1.0,0.2736842105263158,0.7210526315789474
"                                                        Facultad de Ciencias Astronómicas y Geofísicas (UNLP-IALP-CONICET), 1900 La Plata, Argentina",56.0,0.5540540540540541,0.44594594594594594,11.0,1.0,0.29473684210526313,0.2210526315789474
"                                                    Received December 28, 2020; accepted March 25, 2021",52.0,0.42718446601941745,0.5728155339805825,8.0,1.0,0.2736842105263158,0.45789473684210524
arXiv:2101.01660v3 [astro-ph.GA] 8 Apr 2021,0.0,0.9069767441860465,0.09302325581395354,5.0,1.0,0.0,0.7736842105263158
                                                                                                                ABSTRACT,112.0,0.06666666666666667,0.9333333333333333,1.0,1.0,0.5894736842105263,0.368421052631579
"                                                    Aims. We present pyUPMASK, an unsupervised clustering method for stellar clusters that builds upon the original UPMASK package.",52.0,0.6145251396648045,0.3854748603351955,18.0,1.0,0.2736842105263158,0.05789473684210522
                                                    The general approach of this method makes it plausible to be applied to analyses that deal with binary classes of any kind as long as,52.0,0.5891891891891892,0.41081081081081083,25.0,1.0,0.2736842105263158,0.02631578947368418
                                                    the fundamental hypotheses are met. The code is written entirely in Python and is made available through a public repository.,52.0,0.5988700564971752,0.4011299435028248,20.0,1.0,0.2736842105263158,0.06842105263157894
                                                    Methods. The core of the algorithm follows the method developed in UPMASK but introduces several key enhancements. These,52.0,0.5988372093023255,0.40116279069767447,18.0,1.0,0.2736842105263158,0.09473684210526312
"                                                    enhancements not only make pyUPMASK more general, they also improve its performance considerably.",52.0,0.5704697986577181,0.4295302013422819,13.0,1.0,0.2736842105263158,0.21578947368421053
                                                    Results. We thoroughly tested the performance of pyUPMASK on 600 synthetic clusters affected by varying degrees of contamination,52.0,0.6166666666666667,0.3833333333333333,18.0,1.0,0.2736842105263158,0.052631578947368474
"                                                    by field stars. To assess the performance, we employed six different statistical metrics that measure the accuracy of probabilistic",52.0,0.6174863387978142,0.3825136612021858,19.0,1.0,0.2736842105263158,0.0368421052631579
                                                    classification.,52.0,0.22388059701492538,0.7761194029850746,1.0,1.0,0.2736842105263158,0.6473684210526316
"                                                    Conclusions. Our results show that pyUPMASK is better performant than UPMASK for every statistical performance metric, while",52.0,0.6136363636363636,0.38636363636363635,17.0,1.0,0.2736842105263158,0.0736842105263158
                                                    still managing to be many times faster.,52.0,0.3626373626373626,0.6373626373626373,7.0,1.0,0.2736842105263158,0.5210526315789474
                                                    Key words. open clusters and associations: general – methods: data analysis – methods: statistical – open clusters and associations:,52.0,0.6195652173913043,0.3804347826086957,19.0,1.0,0.2736842105263158,0.03157894736842104
                                                    individual: NGC2516,52.0,0.2535211267605634,0.7464788732394366,2.0,1.0,0.2736842105263158,0.6263157894736842
                                              1. Introduction                                                           probabilities was presented (Balaguer-Núñez et al. 2020)1 . More,46.0,0.3804347826086957,0.6195652173913043,11.0,30.0,0.24210526315789474,0.03157894736842104
                                                                                                                        references regarding membership estimation methods can be,120.0,0.288135593220339,0.711864406779661,7.0,1.0,0.631578947368421,0.06842105263157894
"                                                                                                                        found in Krone-Martins & Moitinho (2014, henceforth KMM14)",120.0,0.28651685393258425,0.7134831460674158,8.0,1.0,0.631578947368421,0.06315789473684208
                                              Galactic open clusters are of great importance for the study of,46.0,0.48623853211009177,0.5137614678899083,11.0,1.0,0.24210526315789474,0.4263157894736842
                                                                                                                        and Perren et al. (2015).,120.0,0.14482758620689656,0.8551724137931034,5.0,1.0,0.631578947368421,0.23684210526315785
"                                              the Galaxy’s chemical evolution, structure, and dynamics; these",46.0,0.5137614678899083,0.4862385321100917,8.0,1.0,0.24210526315789474,0.4263157894736842
                                              sources also provide test beds for astrophysical codes that model             The Unsupervised Photometric Membership Assignment in,46.0,0.5875706214689266,0.4124293785310734,16.0,7.0,0.24210526315789474,0.06842105263157894
"                                              the evolution of stars. Located largely on the disk of the Milky          Stellar Clusters algorithm (UPMASK), originally presented in",46.0,0.5944444444444444,0.40555555555555556,19.0,6.0,0.24210526315789474,0.052631578947368474
"                                              Way, analyses of open clusters is severely hindered by the pres-          KMM14, has the advantage of being not only nonparametric,",46.0,0.5819209039548022,0.4180790960451978,20.0,6.0,0.24210526315789474,0.06842105263157894
"                                              ence of contaminating field stars, located in the foreground and          but also unsupervised. This means that no a priori selection of",46.0,0.5901639344262295,0.4098360655737705,21.0,6.0,0.24210526315789474,0.0368421052631579
"                                              background of the object of interest. These stars are projected           field stars is required to serve as a comparison model, which",46.0,0.580110497237569,0.419889502762431,21.0,6.0,0.24210526315789474,0.047368421052631615
                                              on the observed field of view and end up deeply mixed with the            is generally the case in the previously mentioned methods. Al-,46.0,0.5659340659340659,0.4340659340659341,23.0,7.0,0.24210526315789474,0.04210526315789476
                                              cluster members. The process of disentangling these two classes           though UPMASK was motivated by the need of assigning clus-,46.0,0.5842696629213483,0.4157303370786517,19.0,6.0,0.24210526315789474,0.06315789473684208
"                                              of elements, of members from nonmembers (i.e., field stars), can          ter memberships from photometric data, KMM14 had pointed",46.0,0.5909090909090909,0.40909090909090906,18.0,6.0,0.24210526315789474,0.0736842105263158
                                              be referred to as “decontamination”. A proper decontamination             out that the method is general and could be easily applied to,46.0,0.574585635359116,0.425414364640884,20.0,7.0,0.24210526315789474,0.047368421052631615
                                              of the cluster region is a key previous step to the analysis of           other data types and clusters of objects. Recent examples of,46.0,0.5666666666666667,0.43333333333333335,23.0,6.0,0.24210526315789474,0.052631578947368474
"                                              the cluster sequence in search of fundamental parameters (e.g.,           UPMASK used on proper motions (and parallax data) can be",46.0,0.5795454545454546,0.4204545454545454,19.0,6.0,0.24210526315789474,0.0736842105263158
"                                              metallicity, age, distance and extinction) that characterize the          found in Cantat-Gaudin et al. (2018a), Cantat-Gaudin et al.",46.0,0.6033519553072626,0.3966480446927374,17.0,6.0,0.24210526315789474,0.05789473684210522
"                                              open cluster. This analysis, which is often performed in photo-           (2018b), Cantat-Gaudin et al. (2019), Carrera et al. (2019), and",46.0,0.592391304347826,0.40760869565217395,20.0,6.0,0.24210526315789474,0.03157894736842104
"                                              metric space, requires a sequence that is as complete as possible,        Yontan et al. (2019). In the six years since its publication, the",46.0,0.5945945945945946,0.4054054054054054,23.0,5.0,0.24210526315789474,0.02631578947368418
                                              but also as free of contaminating field stars (nonmembers) as             KMM14 article has been referenced almost 50 times; this work,46.0,0.5722222222222222,0.4277777777777778,20.0,7.0,0.24210526315789474,0.052631578947368474
                                              possible. The goal of a decontamination algorithm is to obtain a          has also been applied to stellar proper motions and to study clus-,46.0,0.5860215053763441,0.4139784946236559,23.0,6.0,0.24210526315789474,0.021052631578947323
"                                              subset of stars that fulfills both these conditions simultaneously.       ters of galaxies, which indicates a wide adoption by the astro-",46.0,0.6120218579234973,0.3879781420765027,20.0,4.0,0.24210526315789474,0.0368421052631579
                                                                                                                        physical community.,120.0,0.12949640287769784,0.8705035971223022,2.0,1.0,0.631578947368421,0.2684210526315789
"                                                  Over the years, a handful of decontamination algorithms                   In this work we present an improved version of the original",50.0,0.5300546448087432,0.4699453551912568,19.0,10.0,0.2631578947368421,0.0368421052631579
"                                              have been presented in the stellar cluster literature. Most of these      UPMASK algorithm, which we call pyUPMASK because it is",46.0,0.5977011494252874,0.4022988505747126,20.0,4.0,0.24210526315789474,0.08421052631578951
                                              are variations of the Vasilevskis-Sanders method (Vasilevskis             written entirely in Python. We believe this new package can be,46.0,0.5879120879120879,0.41208791208791207,18.0,7.0,0.24210526315789474,0.04210526315789476
"                                              et al. 1958; Sanders 1971) applied over proper motions, which             of great use, particularly with the advent of the recent early data",46.0,0.5775401069518716,0.42245989304812837,22.0,7.0,0.24210526315789474,0.015789473684210575
"                                              are generally considered to be much better member discrimina-             release 3 (eDR3, Gaia Collaboration et al. 2020) of the Gaia",46.0,0.5722222222222222,0.4277777777777778,20.0,7.0,0.24210526315789474,0.052631578947368474
                                              tors than photometry. Nonparametric approaches have also been,46.0,0.5046728971962616,0.4953271028037384,8.0,1.0,0.24210526315789474,0.4368421052631579
                                              developed (Cabrera-Cano & Alfaro 1990; Javakhishvili et al.               1,46.0,0.4380165289256198,0.5619834710743802,9.0,8.0,0.24210526315789474,0.3631578947368421
                                                                                                                          Clusterix      2.0:     http://clusterix.cab.inta-csic.es/,122.0,0.2611111111111111,0.7388888888888889,3.0,6.0,0.6421052631578947,0.052631578947368474
                                              2006) and even an interactive tool to determine membership                clusterix/,46.0,0.46153846153846156,0.5384615384615384,10.0,9.0,0.24210526315789474,0.3157894736842105
"                                                                                                                                                                  Article number, page 1 of 14",162.0,0.12105263157894737,0.8789473684210526,6.0,1.0,0.8526315789473684,0.0
avr_spaces,56.215384615384615,1.0,0.0,1.0,1.0,0.29587044534412954,0.9473684210526316
                                                  A&A proofs: manuscript no. pera_etal,50.0,0.37209302325581395,0.627906976744186,5.0,1.0,0.2631578947368421,0.5473684210526315
mission (Gaia Collaboration et al. 2016). This package is made      main parts that make up the core of the algorithm: the clustering,0.0,0.8045112781954887,0.19548872180451127,22.0,4.0,0.0,0.30000000000000004
"available as a stand-alone code, but it will also be included in    method (KMS, as stated before), and the random field rejection",0.0,0.8153846153846154,0.18461538461538463,22.0,3.0,0.0,0.3157894736842105
an upcoming release of our Automated Stellar Cluster Analysis       method (henceforth: RFR). The clustering method is applied on,0.0,0.8217054263565892,0.17829457364341084,18.0,4.0,0.0,0.32105263157894737
"tool (ASteCA, Perren et al. 2015). Throughout the article we        the nonpositional features (e.g. photometry and proper motions),",0.0,0.8181818181818182,0.18181818181818177,18.0,5.0,0.0,0.3052631578947368
refer to statistical clusters as simply clusters and explicitly     and separates the cluster data into N clusters. The N value is de-,0.0,0.8134328358208955,0.18656716417910446,22.0,3.0,0.0,0.2947368421052632
distinguish them from stellar clusters when required.               termined by a parameter that determines the number of elements,0.0,0.7692307692307693,0.23076923076923073,17.0,8.0,0.0,0.3157894736842105
"                                                                    that should be contained in each cluster. That is, dividing the to-",68.0,0.4148148148148148,0.5851851851851853,12.0,1.0,0.35789473684210527,0.2894736842105263
"     This paper is organized as follows: In Section 2 we give a     tal number of stars by this value gives N, the final number of",5.0,0.7461538461538462,0.25384615384615383,25.0,3.0,0.02631578947368421,0.3157894736842105
brief summary of the UPMASK algorithm and present the de-           clusters that are generated.,0.0,0.7604166666666666,0.23958333333333337,14.0,6.0,0.0,0.49473684210526314
"tails of the enhancements introduced in our code. Section 3 in-          After the clustering method is applied, the RFR method",0.0,0.7795275590551181,0.22047244094488194,20.0,6.0,0.0,0.3315789473684211
"troduces the synthetic cluster sample used in the analysis, and     serves the purpose of filtering those clusters identified by the",0.0,0.8257575757575758,0.1742424242424242,20.0,3.0,0.0,0.3052631578947368
describes the selected statistical performance metrics employed     KMS that are consistent with a random uniform distribution of,0.0,0.8449612403100775,0.15503875968992253,17.0,3.0,0.0,0.32105263157894737
to assess the behavior of UPMASK and pyUPMASK. The re-              elements. This consistency is assessed in UPMASK by means,0.0,0.752,0.248,19.0,8.0,0.0,0.3421052631578947
"sults are summarized in Section 4. Finally, our conclusions are     of a two-dimensional kernel density estimation (KDE) analysis.",0.0,0.8384615384615385,0.16153846153846152,18.0,3.0,0.0,0.3157894736842105
given in Section 5.                                                 In short: the KDE of the coordinates space of each cluster,0.0,0.5079365079365079,0.4920634920634921,15.0,25.0,0.0,0.33684210526315794
                                                                    (identified by the KMS in the previous step) is compared with,68.0,0.3953488372093023,0.6046511627906976,11.0,1.0,0.35789473684210527,0.32105263157894737
                                                                    the KDE of a two-dimensional uniform distribution in the same,68.0,0.40310077519379844,0.5968992248062015,10.0,1.0,0.35789473684210527,0.32105263157894737
"2. Methods                                                          range. If these are deemed to be similar enough, the cluster is",0.0,0.46564885496183206,0.5343511450381679,14.0,30.0,0.0,0.31052631578947365
"We present a brief description of the general algorithm used        discarded as a realization of a random selection of field stars,",0.0,0.7954545454545454,0.20454545454545459,21.0,5.0,0.0,0.3052631578947368
in UPMASK as well as the major enhancements introduced in           and all its stars are assigned a value of 0. Those clusters that,0.0,0.7575757575757576,0.24242424242424243,23.0,6.0,0.0,0.3052631578947368
pyUPMASK. Both methods are open source and their codes can          survive the RFR process are kept for a subsequent iteration,0.0,0.7795275590551181,0.22047244094488194,20.0,6.0,0.0,0.3315789473684211
"be found in their respective public repositories.2,3                of the inner loop. When no more clusters are rejected and the",0.0,0.7441860465116279,0.2558139534883721,19.0,9.0,0.0,0.32105263157894737
"                                                                    inner loop is finished, all the stars within surviving clusters are",68.0,0.4222222222222222,0.5777777777777777,11.0,1.0,0.35789473684210527,0.2894736842105263
"                                                                    assigned a value of 1. After this, a new iteration of the outer",68.0,0.3893129770992366,0.6106870229007634,13.0,1.0,0.35789473684210527,0.31052631578947365
2.1. The UPMASK algorithm                                           loop is initiated. The final probabilities assigned to each star are,0.0,0.5882352941176471,0.4117647058823529,15.0,22.0,0.0,0.28421052631578947
"                                                                    simply the averages of the (0, 1) values assigned by the inner",68.0,0.3923076923076923,0.6076923076923078,12.0,1.0,0.35789473684210527,0.3157894736842105
The UPMASK package is described in full in KMM14 and we,0.0,0.8181818181818182,0.18181818181818177,11.0,1.0,0.0,0.7105263157894737
                                                                    loop at each run of the outer loop.,68.0,0.27184466019417475,0.7281553398058253,8.0,1.0,0.35789473684210527,0.45789473684210524
do not repeat it in this work. We give instead a summary of the,0.0,0.7936507936507936,0.2063492063492064,14.0,1.0,0.0,0.668421052631579
most relevant parts and of its core algorithm. The original article,0.0,0.8507462686567164,0.14925373134328357,11.0,1.0,0.0,0.6473684210526316
                                                                         The two parameters mentioned above are the most important,73.0,0.3769230769230769,0.6230769230769231,9.0,1.0,0.38421052631578945,0.3157894736842105
provides a more detailed description.,0.0,0.8918918918918919,0.10810810810810811,5.0,1.0,0.0,0.8052631578947369
"                                                                    parameters in UPMASK, since varying their value can substan-",68.0,0.40625,0.59375,9.0,1.0,0.35789473684210527,0.3263157894736842
                                                                    tially affect the performance of the method. We comment on how,68.0,0.4,0.6,11.0,1.0,0.35789473684210527,0.3157894736842105
     Assigning probability memberships to the two classes of,5.0,0.8,0.19999999999999996,8.0,1.0,0.02631578947368421,0.6842105263157895
                                                                    we selected these parameters in Sect 3.3.,68.0,0.3211009174311927,0.6788990825688073,7.0,1.0,0.35789473684210527,0.4263157894736842
elements within a stellar cluster field (members and field stars),0.0,0.8615384615384616,0.1384615384615384,10.0,1.0,0.0,0.6578947368421053
"is a notably complicated problem for two main reasons. First,",0.0,0.8524590163934426,0.14754098360655743,10.0,1.0,0.0,0.6789473684210526
the classes are usually very much imbalanced. This means that       2.2. The pyUPMASK algorithm,0.0,0.8,0.19999999999999996,14.0,4.0,0.0,0.5
one of the classes (field stars) can make up a lot more than,0.0,0.8,0.19999999999999996,13.0,1.0,0.0,0.6842105263157895
"50% of the total dataset. In some extreme cases, the frame of       An obvious difference between pyUPMASK and UPMASK is",0.0,0.7916666666666666,0.20833333333333337,20.0,4.0,0.0,0.368421052631579
"an observed stellar cluster can consist of over 90% of field stars  that the former is written entirely in Python4 instead of R5 , as is",0.0,0.8088235294117647,0.19117647058823528,26.0,2.0,0.0,0.28421052631578947
"and less than 10% of actual true members. Even worse, this          the case with UPMASK. We believe that this is a considerable",0.0,0.765625,0.234375,22.0,6.0,0.0,0.3263157894736842
"information (i.e., the true balance) cannot be assumed to be        advantage given the noticeable shift of the astrophysical commu-",0.0,0.8106060606060606,0.18939393939393945,19.0,5.0,0.0,0.3052631578947368
"known a priori. Second, the two classes are deeply entangled.       nity toward the Python language in recent years. This is made ev-",0.0,0.7969924812030075,0.20300751879699253,22.0,4.0,0.0,0.30000000000000004
This is particularly true in the two-dimensional coordinates        ident by large Python-based projects such as Astropy6 (Astropy,0.0,0.823076923076923,0.17692307692307696,17.0,5.0,0.0,0.3157894736842105
space where members and field stars are mixed throughout the        Collaboration et al. 2013; Price-Whelan et al. 2018) and inter-,0.0,0.8015267175572519,0.1984732824427481,20.0,5.0,0.0,0.31052631578947365
entire cluster region. Off the shelf clustering methods normally    national conferences such as Python in Astronomy7 . A recent,0.0,0.8359375,0.1640625,19.0,3.0,0.0,0.3263157894736842
assume that there is some kind of frontier that largely separates   survey found that Python is the most popular programming lan-,0.0,0.8294573643410853,0.1705426356589147,21.0,2.0,0.0,0.32105263157894737
the classes with minimal overlap. This is not the case in stellar   guage in the astronomical community (Momcheva & Tollerud,0.0,0.8306451612903226,0.16935483870967738,20.0,2.0,0.0,0.34736842105263155
clusters analysis. The UPMASK algorithm deals with both of          2015; Tollerud et al. 2019).,0.0,0.7708333333333334,0.22916666666666663,14.0,6.0,0.0,0.49473684210526314
"these issues in a clever and effective way, by taking advantage          The general structure of pyUPMASK closely follows the",0.0,0.7857142857142857,0.2142857142857143,19.0,6.0,0.0,0.33684210526315794
of the fact that we can approximate the distribution of field stars UPMASK algorithm: an outer loop containing an inner loop that,0.0,0.8372093023255814,0.16279069767441856,22.0,1.0,0.0,0.32105263157894737
in the coordinates space with a uniform model. This is further      applies the cluster identification and rejection methods. What,0.0,0.823076923076923,0.17692307692307696,19.0,4.0,0.0,0.3157894736842105
"discussed in Sect. 2.2.2.                                           sets these two algorithms apart is twofold: First, pyUPMASK",0.0,0.5748031496062992,0.4251968503937008,13.0,22.0,0.0,0.3315789473684211
"                                                                    supports almost a dozen clustering methods, while UPMASK",68.0,0.3951612903225806,0.6048387096774194,8.0,1.0,0.35789473684210527,0.34736842105263155
"     The UPMASK algorithm is composed of two main blocks:           only supports KMS; and second, pyUPMASK contains three",5.0,0.7459016393442623,0.25409836065573765,17.0,6.0,0.02631578947368421,0.35789473684210527
an outer loop and an inner loop. The outer loop is responsible      added analysis blocks that are not present in UPMASK. In Fig. 1,0.0,0.7862595419847328,0.2137404580152672,24.0,4.0,0.0,0.31052631578947365
for taking into account the uncertainties in the data and rerun-    we show the complete flow chart of the pyUPMASK algorithm.,0.0,0.8174603174603174,0.18253968253968256,21.0,3.0,0.0,0.33684210526315794
ning the inner loop a manually fixed number of times; these un-     The blocks indicated in violet are those that are either enhanced,0.0,0.8045112781954887,0.19548872180451127,23.0,3.0,0.0,0.30000000000000004
certainties are optional and turned off by default. The latter is   or added in this work. The enhanced clustering methods block,0.0,0.828125,0.171875,21.0,2.0,0.0,0.3263157894736842
"required because of the inherent stochasticity of the K-means       and the three added blocks are detailed in Sects 2.2.1, 2.2.2,",0.0,0.8076923076923077,0.1923076923076923,20.0,4.0,0.0,0.3157894736842105
"(KMS) method (MacQueen 1967), employed by the inner loop.           2.2.3, and 2.2.4, respectively. The remaining portions of the",0.0,0.7906976744186046,0.2093023255813954,18.0,6.0,0.0,0.32105263157894737
The number of runs for the outer loop is one of the two most im-    code are mostly equivalent to those described in KMM14 for,0.0,0.7857142857142857,0.2142857142857143,25.0,3.0,0.0,0.33684210526315794
portant parameters in the algorithm. The inner loop holds the two,0.0,0.8461538461538461,0.15384615384615385,11.0,1.0,0.0,0.6578947368421053
                                                                     4,69.0,0.014285714285714285,0.9857142857142858,1.0,1.0,0.3631578947368421,0.631578947368421
                                                                       https://www.python.org/,71.0,0.24468085106382978,0.7553191489361702,1.0,1.0,0.3736842105263158,0.5052631578947369
 2                                                                   5,1.0,0.02857142857142857,0.9714285714285714,2.0,34.0,0.005263157894736842,0.631578947368421
   UPMASK:        https://cran.r-project.org/web/packages/             https://www.r-project.org/,3.0,0.7525773195876289,0.24742268041237114,3.0,11.0,0.015789473684210527,0.4894736842105263
                                                                     6,69.0,0.014285714285714285,0.9857142857142858,1.0,1.0,0.3631578947368421,0.631578947368421
UPMASK/                                                                http://www.astropy.org,0.0,0.3118279569892473,0.6881720430107527,2.0,33.0,0.0,0.5105263157894737
 3                                                                   7,1.0,0.02857142857142857,0.9714285714285714,2.0,34.0,0.005263157894736842,0.631578947368421
   pyUPMASK: https://github.com/msolpera/pyUPMASK                      http://openastronomy.org/pyastro/,3.0,0.75,0.25,3.0,12.0,0.015789473684210527,0.4526315789473684
"Article number, page 2 of 14",0.0,0.8214285714285714,0.1785714285714286,6.0,1.0,0.0,0.8526315789473684
avr_spaces,14.513157894736842,1.0,0.0,1.0,1.0,0.07638504155124654,0.9473684210526316
                                 M. S. Pera et al.: pyUPMASK: An improved unsupervised clustering algorithm,33.0,0.5981308411214953,0.4018691588785047,11.0,1.0,0.1736842105263158,0.4368421052631579
"                                                                          UPMASK and, for the sake of brevity, we do not repeat their",74.0,0.3609022556390977,0.6390977443609023,12.0,1.0,0.3894736842105263,0.30000000000000004
                                                                          details or purpose in this work.,74.0,0.25471698113207547,0.7452830188679245,6.0,1.0,0.3894736842105263,0.4421052631578948
                                                                          2.2.1. Clustering methods,74.0,0.23232323232323232,0.7676767676767677,3.0,1.0,0.3894736842105263,0.4789473684210527
                                                                          While UPMASK supports the KMS method exclusively (as,74.0,0.35714285714285715,0.6428571428571428,8.0,1.0,0.3894736842105263,0.33684210526315794
"                                                                          of the current version 1.2), pyUPMASK relies on the Python",74.0,0.3712121212121212,0.6287878787878788,10.0,1.0,0.3894736842105263,0.3052631578947368
                                                                          library scikit-learn8 (Pedregosa et al. 2011a) for the imple-,74.0,0.3925925925925926,0.6074074074074074,9.0,1.0,0.3894736842105263,0.2894736842105263
                                                                          mentation of most of the supported clusterings methods. This,74.0,0.3880597014925373,0.6119402985074627,9.0,1.0,0.3894736842105263,0.2947368421052632
                                                                          library includes around a dozen different clustering methods for,74.0,0.4057971014492754,0.5942028985507246,9.0,1.0,0.3894736842105263,0.27368421052631575
"                                                                          unlabeled data, which are all available to use in pyUPMASK.",74.0,0.37593984962406013,0.6240601503759399,10.0,1.0,0.3894736842105263,0.30000000000000004
                                                                          Eventually this can be extended to support even more methods,74.0,0.3805970149253731,0.6194029850746269,10.0,1.0,0.3894736842105263,0.2947368421052632
                                                                          in future releases of the code via the PyClustering library9 .,74.0,0.38235294117647056,0.6176470588235294,11.0,1.0,0.3894736842105263,0.28421052631578947
"                                                                               Once chosen, the clustering method processes the nonspatial",79.0,0.37681159420289856,0.6231884057971014,8.0,1.0,0.41578947368421054,0.27368421052631575
                                                                          data at the beginning of the inner loop as shown in Fig. 1. The,74.0,0.36496350364963503,0.635036496350365,14.0,1.0,0.3894736842105263,0.2789473684210526
                                                                          number of individual clusters to generate is fixed indirectly,74.0,0.3925925925925926,0.6074074074074074,9.0,1.0,0.3894736842105263,0.2894736842105263
"                                                                          through a user-selected input parameter, as done in UPMASK.",74.0,0.38345864661654133,0.6165413533834587,9.0,1.0,0.3894736842105263,0.30000000000000004
                                                                          Each of these clusters is then analyzed by the RFR method,74.0,0.35877862595419846,0.6412213740458015,11.0,1.0,0.3894736842105263,0.31052631578947365
                                                                          and kept or rejected given its similarity with a random uniform,74.0,0.38686131386861317,0.6131386861313868,11.0,1.0,0.3894736842105263,0.2789473684210526
                                                                          distribution of elements. This is further discussed in Sect. 2.2.2.,74.0,0.41134751773049644,0.5886524822695036,10.0,1.0,0.3894736842105263,0.2578947368421053
                                                                               In Sect 4 we present a suit of tests performed with four of,79.0,0.34057971014492755,0.6594202898550725,13.0,1.0,0.41578947368421054,0.27368421052631575
"                                                                          the methods provided by scikit-learn: KMS, mini batch k-",74.0,0.36923076923076925,0.6307692307692307,9.0,1.0,0.3894736842105263,0.3157894736842105
"                                                                          means (MBK, Sculley 2010), gaussian mixture models (GMM,",74.0,0.3769230769230769,0.6230769230769231,8.0,1.0,0.3894736842105263,0.3157894736842105
"                                                                          Baxter 2010), and agglomerative clustering (AGG, Zepeda-",74.0,0.38461538461538464,0.6153846153846154,7.0,1.0,0.3894736842105263,0.3157894736842105
                                                                          Mendoza & Resendis-Antonio 2013). In addition to these we,74.0,0.37404580152671757,0.6259541984732824,9.0,1.0,0.3894736842105263,0.31052631578947365
                                                                          include tests performed with two methods developed in this,74.0,0.3787878787878788,0.6212121212121212,9.0,1.0,0.3894736842105263,0.3052631578947368
"                                                                          work: the nearest neighbors density method (KNN), which is",74.0,0.3787878787878788,0.6212121212121212,9.0,1.0,0.3894736842105263,0.3052631578947368
                                                                          based on the density peak approach introduced in Rodriguez &,74.0,0.3805970149253731,0.6194029850746269,10.0,1.0,0.3894736842105263,0.2947368421052632
"                                                                          Laio (2014); and the Voronoi (VOR) method, which is based on",74.0,0.373134328358209,0.6268656716417911,11.0,1.0,0.3894736842105263,0.2947368421052632
                                                                          the construction of N-dimensional Voronoi diagrams (Voronoi,74.0,0.39849624060150374,0.6015037593984962,7.0,1.0,0.3894736842105263,0.30000000000000004
"                                                                          1908). The latter three methods (AGG, KNN and VOR) have a",74.0,0.35877862595419846,0.6412213740458015,11.0,1.0,0.3894736842105263,0.31052631578947365
                                                                          characteristic in common: no stochastic process or approxima-,74.0,0.4,0.6,8.0,1.0,0.3894736842105263,0.2894736842105263
"                                                                          tion is employed by any of them. In other words, these methods",74.0,0.375,0.625,12.0,1.0,0.3894736842105263,0.28421052631578947
"                                                                          are deterministic. This means that, for the same input data and",74.0,0.38686131386861317,0.6131386861313868,11.0,1.0,0.3894736842105263,0.2789473684210526
"                                                                          input parameters, different runs lead to one single result. Assum-",74.0,0.40714285714285714,0.5928571428571429,10.0,1.0,0.3894736842105263,0.26315789473684215
                                                                          ing that no data resampling is performed (the default setting in,74.0,0.391304347826087,0.6086956521739131,11.0,1.0,0.3894736842105263,0.27368421052631575
                                                                          both UPMASK and pyUPMASK) the outer loop then needs to,74.0,0.3515625,0.6484375,10.0,1.0,0.3894736842105263,0.3263157894736842
                                                                          be run only once because subsequent runs would produce the,74.0,0.3712121212121212,0.6287878787878788,10.0,1.0,0.3894736842105263,0.3052631578947368
                                                                          same probabilities each time. For this reason we refer to these as,74.0,0.39285714285714285,0.6071428571428572,12.0,1.0,0.3894736842105263,0.26315789473684215
"                                                                          “single-run” methods. As can easily be inferred, these are signif-",74.0,0.40714285714285714,0.5928571428571429,10.0,1.0,0.3894736842105263,0.26315789473684215
"                                                                          icantly faster than UPMASK and the rest of the tested methods,",74.0,0.38235294117647056,0.6176470588235294,11.0,1.0,0.3894736842105263,0.28421052631578947
                                                                          which require multiple outer loop runs.,74.0,0.3008849557522124,0.6991150442477876,6.0,1.0,0.3894736842105263,0.4052631578947369
                                                                               The results obtained with the six selected methods are com-,79.0,0.36231884057971014,0.6376811594202898,10.0,1.0,0.41578947368421054,0.27368421052631575
                                                                          pared to UPMASK results obtained on the same dataset of syn-,74.0,0.373134328358209,0.6268656716417911,11.0,1.0,0.3894736842105263,0.2947368421052632
                                                                          thetic clusters. The synthetic clusters dataset is described in,74.0,0.40145985401459855,0.5985401459854014,9.0,1.0,0.3894736842105263,0.2789473684210526
                                                                          Sect. 3.1.,74.0,0.10714285714285714,0.8928571428571429,2.0,1.0,0.3894736842105263,0.5578947368421052
                                                                          2.2.2. Ripley’s K function,74.0,0.23,0.77,4.0,1.0,0.3894736842105263,0.4736842105263158
"                                                                          After the clusters are generated on the nonspatial data, the RFR",74.0,0.391304347826087,0.6086956521739131,11.0,1.0,0.3894736842105263,0.27368421052631575
                                                                          block is used to filter out those that are consistent with the re-,74.0,0.38571428571428573,0.6142857142857143,13.0,1.0,0.3894736842105263,0.26315789473684215
                                                                          alization of a random uniform distribution on the spatial data,74.0,0.3897058823529412,0.6102941176470589,10.0,1.0,0.3894736842105263,0.28421052631578947
"                                                                          (i.e., coordinates). The hypothesis at work is that field stars are",74.0,0.40425531914893614,0.5957446808510638,11.0,1.0,0.3894736842105263,0.2578947368421053
                                                                          randomly scattered throughout the two spatial dimensions of the,74.0,0.40145985401459855,0.5985401459854014,9.0,1.0,0.3894736842105263,0.2789473684210526
"                                                                          frame, following somewhat closely a uniform distribution. Ac-",74.0,0.4,0.6,8.0,1.0,0.3894736842105263,0.2894736842105263
"                                                                          tual star cluster members, on the other hand, present a more",74.0,0.373134328358209,0.6268656716417911,11.0,1.0,0.3894736842105263,0.2947368421052632
                                                                          densely packed spatial distribution. The latter is of course an ap-,74.0,0.40425531914893614,0.5957446808510638,11.0,1.0,0.3894736842105263,0.2578947368421053
"                                                                          proximation to the real, and unknown, probability distribution of",74.0,0.41007194244604317,0.5899280575539568,9.0,1.0,0.3894736842105263,0.2684210526315789
"                                                                          field stars, but it is still a very reasonable one, as the results show.",74.0,0.4041095890410959,0.595890410958904,14.0,1.0,0.3894736842105263,0.2315789473684211
                                                                           8,75.0,0.013157894736842105,0.9868421052631579,1.0,1.0,0.39473684210526316,0.6
                                                                             https://scikit-learn.org/,77.0,0.24509803921568626,0.7549019607843137,1.0,1.0,0.4052631578947368,0.4631578947368421
                                                                           9,75.0,0.013157894736842105,0.9868421052631579,1.0,1.0,0.39473684210526316,0.6
                                                                             https://pyclustering.github.io,77.0,0.2803738317757009,0.719626168224299,1.0,1.0,0.4052631578947368,0.4368421052631579
"                                                                                                                      Article number, page 3 of 14",118.0,0.15753424657534246,0.8424657534246576,6.0,1.0,0.6210526315789474,0.2315789473684211
Fig. 1. Flow chart of the pyUPMASK code. The enhanced clustering,0.0,0.84375,0.15625,11.0,1.0,0.0,0.6631578947368422
block and the analysis blocks added in this work are indicated in violet.,0.0,0.8356164383561644,0.1643835616438356,13.0,1.0,0.0,0.6157894736842106
avr_spaces,70.9375,1.0,0.0,1.0,1.0,0.37335526315789475,0.9473684210526316
                                                    A&A proofs: manuscript no. pera_etal,52.0,0.36363636363636365,0.6363636363636364,5.0,1.0,0.2736842105263158,0.5368421052631579
     The UPMASK algorithm employs a KDE-based method to                   The pyUPMASK algorithm employs the astropy imple-,5.0,0.6991869918699187,0.30081300813008127,15.0,10.0,0.02631578947368421,0.3526315789473684
"characterize the distribution of each cluster found in the spatial   mentation of the K function, which includes the required edge",0.0,0.8384615384615385,0.16153846153846152,20.0,2.0,0.0,0.3157894736842105
dimensions. This distribution is then compared to that of thou-      corrections for points that are located close to the domain bound-,0.0,0.8148148148148148,0.18518518518518523,21.0,4.0,0.0,0.2894736842105263
"sands of random uniform distributions generated in the same          aries. Compared to the UPMASK KDE test, the K function is not",0.0,0.7769230769230769,0.22307692307692306,21.0,6.0,0.0,0.3157894736842105
"two-dimensional range and with the same number of elements.          only a more natural choice for this task, it is also orders of mag-",0.0,0.7720588235294118,0.2279411764705882,23.0,6.0,0.0,0.28421052631578947
"After that, a “KDE distance” is obtained by comparing their          nitude faster.",0.0,0.7590361445783133,0.24096385542168675,12.0,6.0,0.0,0.5631578947368421
"means, maximum, and standard deviation values. If the distance",0.0,0.8709677419354839,0.12903225806451613,9.0,1.0,0.0,0.6736842105263158
between both distributions is less than a user-defined threshold,0.0,0.875,0.125,9.0,1.0,0.0,0.6631578947368422
                                                                     2.2.3. Gaussian-Uniform mixture model,69.0,0.32075471698113206,0.679245283018868,4.0,1.0,0.3631578947368421,0.4421052631578948
"parameter, the cluster is considered to be close enough to a real-",0.0,0.8333333333333334,0.16666666666666663,12.0,1.0,0.0,0.6526315789473685
ization of a random uniform distribution. When this condition is     After the RFR block is finished and the fake clusters are re-,0.0,0.8076923076923077,0.1923076923076923,22.0,3.0,0.0,0.3157894736842105
"met, the cluster is rejected as a “fake cluster” (see Fig 1).        jected, only those stars that were found in clusters sufficiently",0.0,0.7910447761194029,0.20895522388059706,22.0,5.0,0.0,0.2947368421052632
     In pyUPMASK we introduce Ripley’s K function (Ripley            different from a random uniform distribution of points are kept.,5.0,0.7518796992481203,0.24812030075187974,18.0,7.0,0.02631578947368421,0.30000000000000004
"1976, 1979) to assess the closeness of a cluster to a random uni-    This dataset of stars is nonetheless still affected by contami-",0.0,0.8106060606060606,0.18939393939393945,23.0,3.0,0.0,0.3052631578947368
form distribution. This function is defined as                       nation from field stars that could not be removed. This is be-,0.0,0.6946564885496184,0.30534351145038163,19.0,12.0,0.0,0.31052631578947365
"                                                                     cause these field stars were, by chance, associated with a cluster",69.0,0.4148148148148148,0.5851851851851853,11.0,1.0,0.3631578947368421,0.2894736842105263
               N N                                                   composed mainly of true star cluster members and thus not re-,15.0,0.4076923076923077,0.5923076923076923,13.0,26.0,0.07894736842105263,0.3157894736842105
"           A XX                                                      jected. We developed a method to clean this region, applied to",11.0,0.4198473282442748,0.5801526717557253,13.0,28.0,0.05789473684210526,0.31052631578947365
"R̂(r) =              I(di j < r)ei j ,                           (1)",0.0,0.3088235294117647,0.6911764705882353,9.0,21.0,0.0,0.6421052631578947
"          N 2 i j,i                                                  the two-dimensional coordinates space that we call GUMM, be-",10.0,0.4496124031007752,0.5503875968992248,13.0,26.0,0.05263157894736842,0.32105263157894737
                                                                     cause it based on fitting a Gaussian-uniform mixture model to,69.0,0.4,0.6,10.0,1.0,0.3631578947368421,0.3157894736842105
"where A is the area of the domain (our observed frame), N is         the dataset. This can be thought of as a simpler version of the",0.0,0.75,0.25,26.0,5.0,0.0,0.3052631578947368
"the number of points within it, di j is the distance between points  spatial plus proper motions space modelization found in previ-",0.0,0.8320610687022901,0.16793893129770987,22.0,2.0,0.0,0.31052631578947365
"i, j, I is a function that results in 1 if the condition is met and  ous works, for example, Jones & Walker (1988).",0.0,0.7913043478260869,0.20869565217391306,24.0,2.0,0.0,0.39473684210526316
"0 otherwise, ei j is the edge correction (if required), and r is the      A D-dimensional Gaussian distribution can be written as",0.0,0.7984496124031008,0.20155038759689925,22.0,4.0,0.0,0.32105263157894737
scale at which the R̂ function is calculated.,0.0,0.8444444444444444,0.15555555555555556,8.0,1.0,0.0,0.7631578947368421
     Ripley’s K function is employed to test for complete spa-                                                                   !,5.0,0.3769230769230769,0.6230769230769231,11.0,34.0,0.02631578947368421,0.3157894736842105
                                                                                           1                1,91.0,0.01834862385321101,0.981651376146789,2.0,9.0,0.4789473684210526,0.4263157894736842
"tial randomness (CSR), also called homogeneous Poisson point         N(x|µ, Σ) =                       exp − (x − µ)T Σ−1 (x − µ) ,  (4)",0.0,0.6176470588235294,0.38235294117647056,22.0,17.0,0.0,0.28421052631578947
"process, which basically consist of points randomly located on                       (2π)D/2 |Σ|1/2         2",0.0,0.6238532110091743,0.37614678899082565,12.0,16.0,0.0,0.4263157894736842
a given domain. In a two-dimensional space it is trivial to prove,0.0,0.8307692307692308,0.16923076923076918,12.0,1.0,0.0,0.6578947368421053
"                                                                     where x is the D-dimensional data vector, and (µ, Σ) are the mean",69.0,0.39552238805970147,0.6044776119402986,13.0,1.0,0.3631578947368421,0.2947368421052632
"that if points are distributed following CSR, then K(r) equals",0.0,0.8548387096774194,0.14516129032258063,10.0,1.0,0.0,0.6736842105263158
"                                                                     and covariance matrix. A GMM with K components (i.e., Gaus-",69.0,0.390625,0.609375,10.0,1.0,0.3631578947368421,0.3263157894736842
πr2 (Streib & Davis 2011). The K function is thus a perfect,0.0,0.8135593220338984,0.18644067796610164,12.0,1.0,0.0,0.6894736842105262
                                                                     sians) is defined as,69.0,0.19101123595505617,0.8089887640449438,4.0,1.0,0.3631578947368421,0.531578947368421
match for our intended usage which is precisely to test if a set of,0.0,0.8059701492537313,0.19402985074626866,14.0,1.0,0.0,0.6473684210526316
points (stars) are distributed following uniform spatial random-,0.0,0.890625,0.109375,8.0,1.0,0.0,0.6631578947368422
ness. We employ the form of the K function given by                             X K,0.0,0.5180722891566265,0.4819277108433735,13.0,15.0,0.0,0.5631578947368421
"                                                                     ρGMM =          πi N (x|µi , Σi ) ,                             (5)",69.0,0.15441176470588236,0.8455882352941176,10.0,20.0,0.3631578947368421,0.28421052631578947
                                                                                 i=1,81.0,0.03571428571428571,0.9642857142857143,1.0,1.0,0.4263157894736842,0.5578947368421052
"L̂(r) = [K̂(r)/π]2 ,                                             (2)",0.0,0.29411764705882354,0.7058823529411764,5.0,23.0,0.0,0.6421052631578947
                                                                     where πi are the weights (or mixing coefficients) associated with,69.0,0.417910447761194,0.582089552238806,10.0,1.0,0.3631578947368421,0.2947368421052632
"which converges to r under CSR. Following Dixon (2014) we            each of the K components. Similar to the GMM, we define the",0.0,0.75,0.25,22.0,7.0,0.0,0.3263157894736842
combine information from several distances (r values) in a single    GUMM as a two-dimensional mixture model composed of a,0.0,0.8278688524590164,0.17213114754098358,19.0,3.0,0.0,0.35789473684210527
"test statistic defined as                                            Gaussian, representing the stellar cluster, and a uniform distri-",0.0,0.5895522388059702,0.4104477611940298,13.0,23.0,0.0,0.2947368421052632
"                                                                     bution, representing the noise due to contaminating field stars.",69.0,0.42105263157894735,0.5789473684210527,9.0,1.0,0.3631578947368421,0.30000000000000004
"L̂m = sup |L̂(r) − r|,                                           (3) The full model is then written as",0.0,0.46078431372549017,0.5392156862745099,14.0,22.0,0.0,0.4631578947368421
         r,9.0,0.1,0.9,1.0,1.0,0.04736842105263158,0.9473684210526316
"where sup is the supremum. Given that the lengths of the ob-         ρGU MM = π0 N (x|µ, Σ) + π1 U[0, 1],                            (6)",0.0,0.5735294117647058,0.42647058823529416,24.0,19.0,0.0,0.28421052631578947
"served frame are normalized by default to the range [0, 1] prior",0.0,0.828125,0.171875,12.0,1.0,0.0,0.6631578947368422
"to processing, the list of distances at which Eq. 3 is calculated    where U[0, 1] is the uniform distribution in the range [0, 1], and",0.0,0.8,0.19999999999999996,25.0,3.0,0.0,0.2894736842105263
"are chosen to be in the range [0, 0.25]. This is the range advised   π x (x = 0, 1) are the unknown weights for each model. No restric-",0.0,0.7777777777777778,0.2222222222222222,29.0,2.0,0.0,0.2894736842105263
"in the Kest function of the spatstat package (Baddeley et al.        tions are imposed on the position, shape, or extension of the 2D",0.0,0.7819548872180451,0.21804511278195493,23.0,5.0,0.0,0.30000000000000004
2015)10 .                                                            Gaussian representing the stellar cluster. Following the recipe,0.0,0.48484848484848486,0.5151515151515151,10.0,31.0,0.0,0.3052631578947368
"     The null hypothesis (H0 ) for the L̂m is that the points        employed by the classic GMM, we use the iterative expectation-",5.0,0.7480916030534351,0.25190839694656486,22.0,5.0,0.02631578947368421,0.31052631578947365
"follow CSR. We need to select a critical value such that if          maximization algorithm (EM, Dempster et al. 1977) to estimate",0.0,0.7769230769230769,0.22307692307692306,21.0,6.0,0.0,0.3157894736842105
"the test is greater than that value, the test is considered to be    these weights as well as the mean and covariance of the 2D",0.0,0.7874015748031497,0.21259842519685035,25.0,3.0,0.0,0.3315789473684211
"statistically significant and H0 is rejected. Such critical values   Gaussian. After the EM algorithm converges to a solution, each",0.0,0.8473282442748091,0.15267175572519087,19.0,2.0,0.0,0.31052631578947365
were estimated by Monte Carlo simulations in Ripley (1979).          star is assigned a probability of belonging to the 2D Gaussian,0.0,0.7862595419847328,0.2137404580152672,20.0,6.0,0.0,0.31052631578947365
"The pyUPMASK algorithm uses the 1% critical value; that is,          (i.e., to the putative cluster). We then need to decide which stars",0.0,0.7794117647058824,0.22058823529411764,22.0,6.0,0.0,0.28421052631578947
there is a 1% probability of erroneously rejecting H0 (also called   to reject as field stars based on these probability values. To do,0.0,0.8208955223880597,0.17910447761194026,23.0,2.0,0.0,0.2947368421052632
a Type                                                               this the percentile distribution of the probabilities is generated,0.0,0.4666666666666667,0.5333333333333333,11.0,32.0,0.0,0.2894736842105263
       √ I error). This critical value is approximated for L̂m as,7.0,0.7384615384615385,0.2615384615384615,11.0,1.0,0.03684210526315789,0.6578947368421053
"1.68 A/N, where A and N are the area and number of points,           and the value at which the curve begins a sharp climb toward",0.0,0.7364341085271318,0.26356589147286824,25.0,6.0,0.0,0.32105263157894737
respectively. In future releases of the code we plan on integrat-    large probabilities is automatically identified as the probability,0.0,0.8444444444444444,0.15555555555555556,19.0,3.0,0.0,0.2894736842105263
"ing analytical expressions for the critical values, for example,     cut. The value corresponding to the climb in the percentile curve",0.0,0.8283582089552238,0.17164179104477617,20.0,3.0,0.0,0.2947368421052632
those obtained in Lagache et al. (2013) and Marcon et al. (2013).    is estimated with the method developed in the kneebow pack-,0.0,0.8125,0.1875,22.0,3.0,0.0,0.3263157894736842
                                                                     age11 . The user can input a manual value for this probability cut,69.0,0.4,0.6,13.0,1.0,0.3631578947368421,0.2894736842105263
10                                                                   11,0.0,0.056338028169014086,0.9436619718309859,2.0,34.0,0.0,0.6263157894736842
    http://spatstat.org/                                                 https://github.com/georg-un/kneebow,4.0,0.5092592592592593,0.4907407407407407,2.0,25.0,0.021052631578947368,0.43157894736842106
"Article number, page 4 of 14",0.0,0.8214285714285714,0.1785714285714286,6.0,1.0,0.0,0.8526315789473684
avr_spaces,13.37837837837838,1.0,0.0,1.0,1.0,0.07041251778093885,0.9473684210526316
                                  M. S. Pera et al.: pyUPMASK: An improved unsupervised clustering algorithm,34.0,0.5925925925925926,0.40740740740740744,11.0,1.0,0.17894736842105263,0.43157894736842106
                                                                          on to the next segment is the hard binary classification. This,74.0,0.38235294117647056,0.6176470588235294,11.0,1.0,0.3894736842105263,0.28421052631578947
                                                                          means that only probability values of 0 and 1 are assigned up to,74.0,0.37681159420289856,0.6231884057971014,13.0,1.0,0.3894736842105263,0.27368421052631575
                                                                          this stage. The KDE block takes these binary probabilities and,74.0,0.3897058823529412,0.6102941176470589,10.0,1.0,0.3894736842105263,0.28421052631578947
"                                                                          turns them into continuous probabilities in the range [0, 1]. This",74.0,0.4,0.6,11.0,1.0,0.3894736842105263,0.26315789473684215
                                                                          improves the final results in general by assigning more realistic,74.0,0.4028776978417266,0.5971223021582734,10.0,1.0,0.3894736842105263,0.2684210526315789
"                                                                          probability values. Furthermore, this block is essential for",74.0,0.39552238805970147,0.6044776119402986,8.0,1.0,0.3894736842105263,0.2947368421052632
                                                                          single-run clustering methods (defined in Sect 2.2.1). Clustering,74.0,0.4172661870503597,0.5827338129496402,8.0,1.0,0.3894736842105263,0.2684210526315789
                                                                          methods such as KMS or GMM require multiple outer loop,74.0,0.3515625,0.6484375,10.0,1.0,0.3894736842105263,0.3263157894736842
                                                                          runs. The final probabilities are then estimated by averaging,74.0,0.3925925925925926,0.6074074074074074,9.0,1.0,0.3894736842105263,0.2894736842105263
"                                                                          all the binary probability values, which breaks the binarity.",74.0,0.3925925925925926,0.6074074074074074,9.0,1.0,0.3894736842105263,0.2894736842105263
"                                                                          Single-run methods work, as the name indicates, on a single run",74.0,0.38686131386861317,0.6131386861313868,11.0,1.0,0.3894736842105263,0.2789473684210526
"                                                                          of the outer loop. This means that without this block, single-run",74.0,0.39568345323741005,0.60431654676259,11.0,1.0,0.3894736842105263,0.2684210526315789
                                                                          methods would assign probabilities of 0 and 1 exclusively.,74.0,0.3787878787878788,0.6212121212121212,9.0,1.0,0.3894736842105263,0.3052631578947368
                                                                               The KDE probabilities are assigned after a full run of the,79.0,0.35036496350364965,0.6496350364963503,11.0,1.0,0.41578947368421054,0.2789473684210526
"                                                                          inner loop, with all stars classified as either members or non-",74.0,0.38686131386861317,0.6131386861313868,11.0,1.0,0.3894736842105263,0.2789473684210526
                                                                          members. The process is as follows:,74.0,0.27522935779816515,0.7247706422018348,6.0,1.0,0.3894736842105263,0.4263157894736842
                                                                           1. Separates each of those two classes into different sets.,75.0,0.373134328358209,0.6268656716417911,10.0,1.0,0.39473684210526316,0.2947368421052632
"                                                                           2. Estimate the KDE for each class, using all the available data,",75.0,0.38571428571428573,0.6142857142857143,12.0,1.0,0.39473684210526316,0.26315789473684215
"                                                                               that is, coordinates plus the data dimensions used for cluster-",79.0,0.38028169014084506,0.619718309859155,10.0,1.0,0.41578947368421054,0.25263157894736843
"                                                                               ing (photometry, proper motions, etc.).",79.0,0.2966101694915254,0.7033898305084746,5.0,1.0,0.41578947368421054,0.3789473684210526
                                                                           3. Evaluate all the data in the frame in the KDE obtained for,75.0,0.3602941176470588,0.6397058823529411,13.0,1.0,0.39473684210526316,0.28421052631578947
                                                                               each class.,79.0,0.1111111111111111,0.8888888888888888,2.0,1.0,0.41578947368421054,0.5263157894736843
Fig. 2. GUMM process in four steps. Panel a: The set of stars that sur-    4. Use the above evaluations as likelihood estimates in the,0.0,0.7985074626865671,0.20149253731343286,25.0,3.0,0.0,0.2947368421052632
vived the RFR block. Panel b: Probabilities assigned by the GUMM to            Bayesian probability for two exclusive and exhaustive hy-,0.0,0.7794117647058824,0.22058823529411764,20.0,7.0,0.0,0.28421052631578947
all the stars in the frame. Panel c: The method for selecting the prob-,0.0,0.8169014084507042,0.18309859154929575,14.0,1.0,0.0,0.6263157894736842
ability cut value using a percentile plot. Panel d: The final set cleaned,0.0,0.8356164383561644,0.1643835616438356,13.0,1.0,0.0,0.6157894736842106
"                                                                               potheses (i.e., a star belongs to either the members distribu-",79.0,0.375886524822695,0.624113475177305,10.0,1.0,0.41578947368421054,0.2578947368421053
from most of the contaminating field stars.                                    tion or the field stars distribution).,0.0,0.5982905982905983,0.4017094017094017,13.0,19.0,0.0,0.38421052631578945
                                                                               The final cluster membership probability (using uniform,79.0,0.3656716417910448,0.6343283582089552,7.0,1.0,0.41578947368421054,0.2947368421052632
"(or even skip the GUMM altogether), but after extensive testing           equal priors) is written as",0.0,0.7623762376237624,0.2376237623762376,15.0,6.0,0.0,0.46842105263157896
this method has proven to give very good results and it is thus the,0.0,0.8059701492537313,0.19402985074626866,14.0,1.0,0.0,0.6473684210526316
"recommended default. Stars below this value are rejected as con-          Pcl = KDEm /(KDEm + KDEnm ),                                         (7)",0.0,0.547945205479452,0.452054794520548,18.0,26.0,0.0,0.2315789473684211
taminating field stars and the surviving stars are kept as cluster,0.0,0.8484848484848485,0.1515151515151515,11.0,1.0,0.0,0.6526315789473685
members.                                                                  where KDEm and KDEnm are the KDE likelihoods for the mem-,0.0,0.4198473282442748,0.5801526717557253,12.0,34.0,0.0,0.31052631578947365
"     The results of processing a group of stars from a synthetic          bers and nonmembers (field), respectively. The process can be",5.0,0.7555555555555555,0.24444444444444446,20.0,6.0,0.02631578947368421,0.2894736842105263
cluster with the GUMM can be seen in Fig. 2. The plot in                  seen in Fig. 3 for the coordinates dimensions (even though it,0.0,0.7037037037037037,0.2962962962962963,24.0,10.0,0.0,0.2894736842105263
"panel a shows the 2D coordinates space after the RFR block                is applied on all the data dimensions, described in Sect. 3.1).",0.0,0.7372262773722628,0.26277372262773724,22.0,9.0,0.0,0.2789473684210526
"rejects those clusters; this is consistent with a random uniform          The plot in panel a shows the two classes, members and non-",0.0,0.7744360902255639,0.22556390977443608,22.0,6.0,0.0,0.30000000000000004
"distribution. It can be seen that, even after clusters mainly             members, generated after the inner loop is finished. In the plot",0.0,0.7681159420289855,0.23188405797101452,21.0,7.0,0.0,0.27368421052631575
"composed of field stars are rejected, the central overdensity is          in panel b, we show the two-dimensional coordinates KDEs for",0.0,0.7910447761194029,0.20895522388059706,20.0,6.0,0.0,0.2947368421052632
"still visibly contaminated by the surrounding field stars. The            both classes, noting again that this is applied on all the data di-",0.0,0.7730496453900709,0.22695035460992907,22.0,7.0,0.0,0.2578947368421053
plot in panel b shows the probabilities assigned to each star             mensions. The plot in panel c shows the nonbinary Pcl probabil-,0.0,0.7591240875912408,0.24087591240875916,22.0,7.0,0.0,0.2789473684210526
"of belonging to the 2D Gaussian via the GUMM process. In                  ities assigned by the method in the coordinates space. Finally,",0.0,0.7299270072992701,0.27007299270072993,21.0,10.0,0.0,0.2789473684210526
"the plot in panel c, we show the percentile diagram for the               the plot in panel d is equivalent to the plot in panel c, but for the",0.0,0.7132867132867133,0.28671328671328666,28.0,8.0,0.0,0.24736842105263157
"probabilities, where the red line shows the value at which the            proper motions space.",0.0,0.7473684210526316,0.25263157894736843,14.0,7.0,0.0,0.5
"cut is imposed. Finally, the plot in panel d shows the region after",0.0,0.8208955223880597,0.17910447761194026,13.0,1.0,0.0,0.6473684210526316
those stars with probabilities below the aforementioned cut are,0.0,0.873015873015873,0.12698412698412698,9.0,1.0,0.0,0.668421052631579
rejected.                                                                 3. Validation of the method,0.0,0.31683168316831684,0.6831683168316831,6.0,33.0,0.0,0.46842105263157896
                                                                          In order to perform a thorough comparison of the performance of,74.0,0.38686131386861317,0.6131386861313868,11.0,1.0,0.3894736842105263,0.2789473684210526
"     This process, although almost trivial at first glance, greatly       pyUPMASK with that of UPMASK, we applied both methods to",5.0,0.7769230769230769,0.22307692307692306,19.0,4.0,0.02631578947368421,0.3157894736842105
improves the purity of the final sample of estimated true mem-            a large number of synthetic clusters and quantified the results us-,0.0,0.7730496453900709,0.22695035460992907,22.0,7.0,0.0,0.2578947368421053
"bers at very little cost regarding completeness. The hypothesis at        ing numerous statistical metrics. In this section, we describe the",0.0,0.8142857142857143,0.18571428571428572,20.0,5.0,0.0,0.26315789473684215
"work is of course that the putative stellar cluster is more concen-       set of synthetic clusters, the selected metrics, and the reasoning",0.0,0.8071428571428572,0.19285714285714284,22.0,4.0,0.0,0.26315789473684215
"trated in the coordinates space than regular field stars, as previ-       behind the choice of input parameters.",0.0,0.8035714285714286,0.1964285714285714,17.0,4.0,0.0,0.41052631578947374
ously stated.,0.0,0.9230769230769231,0.07692307692307687,2.0,1.0,0.0,0.9315789473684211
                                                                          3.1. Synthetic datasets,74.0,0.21649484536082475,0.7835051546391752,3.0,1.0,0.3894736842105263,0.4894736842105263
2.2.4. Kernel density estimator probabilities,0.0,0.9111111111111111,0.0888888888888889,5.0,1.0,0.0,0.7631578947368421
                                                                          We employed a total of 600 synthetic clusters to analyze the per-,74.0,0.38848920863309355,0.6115107913669064,12.0,1.0,0.3894736842105263,0.2684210526315789
"Once a run of the inner loop is finished, each star in the observed       formance of UPMASK and pyUPMASK, the latter in the six",0.0,0.7734375,0.2265625,24.0,4.0,0.0,0.3263157894736842
field is classified to be either a cluster member or a field star.        configurations mentioned in Sect 2.2.1. This set is divided into,0.0,0.7898550724637681,0.21014492753623193,23.0,5.0,0.0,0.27368421052631575
"Although continuous (spatial) probabilities are assigned in the           a subset of 320 clusters, and another of 280 clusters. The first",0.0,0.7898550724637681,0.21014492753623193,20.0,6.0,0.0,0.27368421052631575
"GUMM step, these are used to apply a coarse classification be-            subset is equivalent to that used in the original UPMASK arti-",0.0,0.7647058823529411,0.23529411764705888,22.0,7.0,0.0,0.28421052631578947
tween members and nonmembers. The information that moves                  cle (KMM14) in the sense that it is composed of clusters with,0.0,0.7333333333333333,0.2666666666666667,20.0,10.0,0.0,0.2894736842105263
"                                                                                                                      Article number, page 5 of 14",118.0,0.15753424657534246,0.8424657534246576,6.0,1.0,0.6210526315789474,0.2315789473684211
avr_spaces,33.22727272727273,1.0,0.0,1.0,1.0,0.1748803827751196,0.9473684210526316
                                                       A&A proofs: manuscript no. pera_etal,55.0,0.3516483516483517,0.6483516483516483,5.0,1.0,0.2894736842105263,0.5210526315789474
Fig. 3. KDE probabilities method shown in the coordinates space. Panel    Fig. 4. Top row: Coordinates and CMD for a PHOT synthetic cluster,0.0,0.8201438848920863,0.17985611510791366,23.0,3.0,0.0,0.2684210526315789
"a: Members and nonmembers, as estimated by the inner loop process.        with moderate CI. Bottom row: Coordinates and vector-point diagram",0.0,0.8142857142857143,0.18571428571428572,20.0,5.0,0.0,0.26315789473684215
Panel b: KDEs for both classes. Panel c: Final Pcl probabilities assigned for a PM synthetic cluster with moderate CI.,0.0,0.8389830508474576,0.1610169491525424,20.0,1.0,0.0,0.3789473684210526
"in the coordinates space. Panel d: Same as panel c, but for proper mo-",0.0,0.8142857142857143,0.18571428571428572,14.0,1.0,0.0,0.631578947368421
tions.,0.0,1.0,0.0,1.0,1.0,0.0,0.968421052631579
                                                                               We selected six metrics that can be divided into two groups,79.0,0.35507246376811596,0.644927536231884,11.0,1.0,0.41578947368421054,0.27368421052631575
                                                                          of three each. The first group consists of strictly proper scoring,74.0,0.4,0.6,11.0,1.0,0.3894736842105263,0.26315789473684215
"synthetic photometry generated with the same process as that              rules, which guarantee that they are only optimized when the",0.0,0.7686567164179104,0.23134328358208955,19.0,8.0,0.0,0.2947368421052632
used in KMM14. We refer to this subset as PHOT hereinafter.               true classification is obtained. This group is composed of the,0.0,0.75,0.25,21.0,8.0,0.0,0.28421052631578947
The second subset contains 280 clusters generated by adding               following metrics:,0.0,0.7391304347826086,0.26086956521739135,11.0,8.0,0.0,0.5157894736842106
synthetic proper motions to all the stars in the frame; we re-,0.0,0.8225806451612904,0.17741935483870963,12.0,1.0,0.0,0.6736842105263158
fer to this subset as PM hereinafter. The idea is to see how              Logarithmic scoring rule:,0.0,0.7171717171717171,0.2828282828282829,16.0,8.0,0.0,0.4789473684210527
the two algorithms handle the case in which only photometry,0.0,0.847457627118644,0.15254237288135597,10.0,1.0,0.0,0.6894736842105262
"is available (i.e., the PHOT dataset), and the increasingly com-                       1 X",0.0,0.6333333333333333,0.3666666666666667,12.0,12.0,0.0,0.5263157894736843
                                                                                            N,92.0,0.010752688172043012,0.989247311827957,1.0,1.0,0.4842105263157895,0.5105263157894737
"mon case (thanks to the Gaia mission) in which proper motions             LS R = 1 +          ytrue log(p) + (1 − ytrue ) log(1 − p),     (8)",0.0,0.6382978723404256,0.36170212765957444,27.0,14.0,0.0,0.2578947368421053
"with very reasonable quality are available (i.e., the PM dataset).                     N i=1",0.0,0.6630434782608695,0.3369565217391305,12.0,11.0,0.0,0.5157894736842106
The performance of UPMASK and pyUPMASK is tested using,0.0,0.8518518518518519,0.14814814814814814,9.0,1.0,0.0,0.7157894736842105
"                                                                          where N is the number of elements, ytrue ∈ {0, 1} is the true",74.0,0.35555555555555557,0.6444444444444444,14.0,1.0,0.3894736842105263,0.2894736842105263
the 600 synthetic clusters obtained by combining the PHOT and,0.0,0.8524590163934426,0.14754098360655743,10.0,1.0,0.0,0.6789473684210526
"                                                                          label, and p= Pr(y=1) is the probability that y=1, that is, the",74.0,0.3795620437956204,0.6204379562043796,12.0,1.0,0.3894736842105263,0.2789473684210526
PM datasets. Clusters were generated with a wide range of field,0.0,0.8412698412698413,0.15873015873015872,11.0,1.0,0.0,0.668421052631579
                                                                          probability that the element belongs to the class identified with a,74.0,0.40425531914893614,0.5957446808510638,11.0,1.0,0.3894736842105263,0.2578947368421053
star contamination. The level of contamination is measured by,0.0,0.8688524590163934,0.1311475409836066,9.0,1.0,0.0,0.6789473684210526
                                                                          1 (Good 1952). The LSR (also called log-loss or cross-entropy),74.0,0.3897058823529412,0.6102941176470589,10.0,1.0,0.3894736842105263,0.28421052631578947
"the contamination index (CI), which is defined as the number of",0.0,0.8412698412698413,0.15873015873015872,11.0,1.0,0.0,0.668421052631579
                                                                          heavily penalizes large differences between ytrue and p.,74.0,0.3769230769230769,0.6230769230769231,8.0,1.0,0.3894736842105263,0.3157894736842105
field stars to cluster members in the frame to match the “con-,0.0,0.8225806451612904,0.17741935483870963,12.0,1.0,0.0,0.6736842105263158
tamination rate” used in KMM14. The maximum CI in our set,0.0,0.8245614035087719,0.17543859649122806,11.0,1.0,0.0,0.7
                                                                          Brier score loss:,74.0,0.16483516483516483,0.8351648351648352,3.0,1.0,0.3894736842105263,0.5210526315789474
of synthetic clusters is 200.,0.0,0.8620689655172413,0.13793103448275867,5.0,1.0,0.0,0.8473684210526315
                                                                                            N,92.0,0.010752688172043012,0.989247311827957,1.0,1.0,0.4842105263157895,0.5105263157894737
     In Fig. 4 we show examples of a PHOT (top) and PM (bot-                           1 X,5.0,0.5,0.5,15.0,14.0,0.02631578947368421,0.5263157894736843
"tom) synthetic clusters, which are generated with moderate con-           BS L = 1 −          (p − ytrue )2 ,                             (9)",0.0,0.5319148936170213,0.46808510638297873,20.0,25.0,0.0,0.2578947368421053
                                                                                       N i=1,87.0,0.043478260869565216,0.9565217391304348,2.0,1.0,0.45789473684210524,0.5157894736842106
tamination (CI≈50).,0.0,0.9473684210526315,0.052631578947368474,2.0,1.0,0.0,0.9
                                                                          which is equivalent to the mean squared error for binary,74.0,0.36153846153846153,0.6384615384615384,10.0,1.0,0.3894736842105263,0.3157894736842105
3.2. Performance metrics                                                  classification; it was originally introduced in Brier (1950).,0.0,0.562962962962963,0.437037037037037,11.0,26.0,0.0,0.2894736842105263
A proper choice for evaluating the classification performance of          H measure:,0.0,0.7738095238095238,0.22619047619047616,11.0,6.0,0.0,0.5578947368421052
a probabilistic model (such as UPMASK or pyUPMASK) is a                                    L,0.0,0.5108695652173914,0.48913043478260865,11.0,19.0,0.0,0.5157894736842106
"debate that carries on even today (Hand 2009; Hernández-Orallo            HMS = 1 −           ,                                         (10)",0.0,0.4642857142857143,0.5357142857142857,15.0,32.0,0.0,0.26315789473684215
                                                                                        Lmax,88.0,0.043478260869565216,0.9565217391304348,1.0,1.0,0.4631578947368421,0.5157894736842106
et al. 2012). Different metrics or scoring rules yield different re-,0.0,0.8529411764705882,0.1470588235294118,11.0,1.0,0.0,0.6421052631578947
"sults regarding the performance of the model (Merkle & Steyvers           where L is the loss function, and Lmax is the maximum loss;",0.0,0.7669172932330827,0.23308270676691734,22.0,6.0,0.0,0.30000000000000004
"2013), which means that relying on a single metric is not rec-            the expression for the loss function is much too mathematically",0.0,0.7664233576642335,0.23357664233576647,22.0,7.0,0.0,0.2789473684210526
"ommended. This is particularly true when dealing with datasets            involved to be presented here, it can be seen in full in Hand",0.0,0.762962962962963,0.23703703703703705,22.0,7.0,0.0,0.2894736842105263
"that can be highly imbalanced, as is our case. We thus chose to           (2009). This is a relatively new metric. It was developed as",0.0,0.753731343283582,0.24626865671641796,24.0,6.0,0.0,0.2947368421052632
"employ multiple metrics. By combining all of these, we expect             a replacement of the popular AUC (area under the receiver",0.0,0.7633587786259542,0.23664122137404575,20.0,7.0,0.0,0.31052631578947365
to obtain a non-biased assessment of the overall performance of           operating characteristic curve) score; now known to be an inco-,0.0,0.7883211678832117,0.21167883211678828,20.0,6.0,0.0,0.2789473684210526
pyUPMASK versus UPMASK.                                                   herent performance measure and thus not recommended (Lobo,0.0,0.5419847328244275,0.4580152671755725,11.0,26.0,0.0,0.31052631578947365
"Article number, page 6 of 14",0.0,0.8214285714285714,0.1785714285714286,6.0,1.0,0.0,0.8526315789473684
avr_spaces,20.566037735849054,1.0,0.0,1.0,1.0,0.10824230387288976,0.9473684210526316
                                 M. S. Pera et al.: pyUPMASK: An improved unsupervised clustering algorithm,33.0,0.5981308411214953,0.4018691588785047,11.0,1.0,0.1736842105263158,0.4368421052631579
et al. 2008; Parker 2011; Hand & Anagnostopoulos 2014). The,0.0,0.847457627118644,0.15254237288135597,10.0,1.0,0.0,0.6894736842105262
HMS automatically handles unbalanced classes by treating the,0.0,0.8833333333333333,0.1166666666666667,8.0,1.0,0.0,0.6842105263157895
misclassification of the smaller class (in our case almost always,0.0,0.8615384615384616,0.1384615384615384,10.0,1.0,0.0,0.6578947368421053
"true members, except for extremely low CI values) as more",0.0,0.8421052631578947,0.1578947368421053,10.0,1.0,0.0,0.7
serious than those of the larger class.,0.0,0.8461538461538461,0.15384615384615385,7.0,1.0,0.0,0.7947368421052632
It is worth noting that the definitions of LSR and BSL were,0.0,0.8135593220338984,0.18644067796610164,12.0,1.0,0.0,0.6894736842105262
altered from their original forms by multiplying by -1 and,0.0,0.8448275862068966,0.15517241379310343,10.0,1.0,0.0,0.6947368421052631
adding plus 1. This way all the metrics defined assign 1 to a,0.0,0.8032786885245902,0.19672131147540983,13.0,1.0,0.0,0.6789473684210526
perfect score.,0.0,0.9285714285714286,0.0714285714285714,2.0,1.0,0.0,0.9263157894736842
    The three metrics in the first group can be used directly on,4.0,0.765625,0.234375,12.0,1.0,0.021052631578947368,0.6631578947368422
"the membership probabilities in the [0, 1] range, resulting from",0.0,0.859375,0.140625,10.0,1.0,0.0,0.6631578947368422
UPMASK or pyUPMASK. The second group defined below,0.0,0.86,0.14,8.0,1.0,0.0,0.736842105263158
consists of scoring rules that are applied to binary classifiers.,0.0,0.8615384615384616,0.1384615384615384,10.0,1.0,0.0,0.6578947368421053
These are the types of metrics used in the original KMM14,0.0,0.8245614035087719,0.17543859649122806,11.0,1.0,0.0,0.7
article and we employ them in this work for consistency12 . In,0.0,0.8225806451612904,0.17741935483870963,12.0,1.0,0.0,0.6736842105263158
the definitions that follow TP is a true positive (a member star,0.0,0.828125,0.171875,12.0,1.0,0.0,0.6631578947368422
"correctly classified as such), TN is a true negative (a field star",0.0,0.8333333333333334,0.16666666666666663,12.0,1.0,0.0,0.6526315789473685
"correctly classified as such), FN is a false negative (a member",0.0,0.8412698412698413,0.15873015873015872,11.0,1.0,0.0,0.668421052631579
"star incorrectly classified as field), and FP is a false positive (a",0.0,0.8382352941176471,0.16176470588235292,12.0,1.0,0.0,0.6421052631578947
field star incorrectly classified as member):,0.0,0.8888888888888888,0.11111111111111116,6.0,1.0,0.0,0.7631578947368421
"True positive rate:                                                   Fig. 5. a, b, c: Boxplot of the combined metrics difference vs. CI",0.0,0.5220588235294118,0.4779411764705882,16.0,26.0,0.0,0.28421052631578947
                                                                      for the 100 synthetic clusters used in the test. Combinations for the,70.0,0.4172661870503597,0.5827338129496402,12.0,1.0,0.3684210526315789,0.2684210526315789
"                                                                      N15 , N25 , N50 values are shown. Panel d: Outer loop convergence anal-",70.0,0.41134751773049644,0.5886524822695036,14.0,1.0,0.3684210526315789,0.2578947368421053
             TP,13.0,0.13333333333333333,0.8666666666666667,1.0,1.0,0.06842105263157895,0.9210526315789473
"T PR =              ,                                           (11)  ysis. The convergence percentile of the nine metrics vs. the number of",0.0,0.4857142857142857,0.5142857142857142,17.0,30.0,0.0,0.26315789473684215
         T P + FN                                                     outer loop run is shown. The black dashed line indicates the 90% con-,9.0,0.4460431654676259,0.5539568345323741,17.0,27.0,0.04736842105263158,0.2684210526315789
                                                                      vergence point.,70.0,0.16470588235294117,0.8352941176470589,2.0,1.0,0.3684210526315789,0.5526315789473684
which is also called sensitivity or recall; it measures the propor-,0.0,0.8507462686567164,0.14925373134328357,11.0,1.0,0.0,0.6473684210526316
tion of true members that are correctly identified.,0.0,0.8627450980392157,0.13725490196078427,8.0,1.0,0.0,0.7315789473684211
                                                                      3.3. Input parameters selection,70.0,0.27722772277227725,0.7227722772277227,4.0,1.0,0.3684210526315789,0.46842105263157896
Positive predictive value:,0.0,0.9230769230769231,0.07692307692307687,3.0,1.0,0.0,0.8631578947368421
                                                                      There are two main parameters in UPMASK and pyUPMASK,70.0,0.36065573770491804,0.639344262295082,9.0,1.0,0.3684210526315789,0.35789473684210527
                                                                      that affect the outcome of the methods: the number of stars per,70.0,0.39097744360902253,0.6090225563909775,12.0,1.0,0.3684210526315789,0.30000000000000004
             TP,13.0,0.13333333333333333,0.8666666666666667,1.0,1.0,0.06842105263157895,0.9210526315789473
"PPV =               ,                                           (12)  cluster and the number of runs of the outer loop. The former,",0.0,0.45038167938931295,0.549618320610687,16.0,30.0,0.0,0.31052631578947365
"         T P + FP                                                     which we refer to as Nclust , was investigated in KMM14, in",9.0,0.4108527131782946,0.5891472868217054,16.0,27.0,0.04736842105263158,0.32105263157894737
                                                                      which the authors concluded that a value between 10 to 25 is,70.0,0.3769230769230769,0.6230769230769231,12.0,1.0,0.3684210526315789,0.3157894736842105
"which is also called precision; it measures how many stars            appropriate. In the latest version (v1.2) of the UPMASK code,",0.0,0.7709923664122137,0.2290076335877863,20.0,7.0,0.0,0.31052631578947365
"classified as members are true members.                               depending on how it is run, the default value for Nclust is either",0.0,0.6470588235294118,0.3529411764705882,19.0,16.0,0.0,0.28421052631578947
                                                                      25 or 5013 . We performed our own tests using 100 synthetic,70.0,0.37209302325581395,0.627906976744186,12.0,1.0,0.3684210526315789,0.32105263157894737
"Matthews correlation coefficient:                                     clusters (50 PHOT and 50 PM) covering the full CI range, se-",0.0,0.6153846153846154,0.3846153846153846,15.0,19.0,0.0,0.3157894736842105
                                                                      lected at random from the full list of 600 mentioned in Sect 3.1.,70.0,0.3925925925925926,0.6074074074074074,13.0,1.0,0.3684210526315789,0.2894736842105263
                        T P × T N − FP × FN                           This set was analyzed with the nine performance metrics,24.0,0.464,0.536,18.0,14.0,0.12631578947368421,0.3421052631578947
"MCC = √                                                     ,   (13)  described in Sect 3.2. In Fig. 5 we show the results obtained for",0.0,0.4666666666666667,0.5333333333333333,18.0,29.0,0.0,0.2894736842105263
"             (T P + FP)(T P + FN)(T N + FP)(T N + FN)                 three Nclust values 15, 25, and 50. We combined all the metrics",13.0,0.6015037593984962,0.3984962406015038,25.0,9.0,0.06842105263157895,0.30000000000000004
                                                                      for the 100 synthetic clusters into one set and subtracted these,70.0,0.40298507462686567,0.5970149253731343,11.0,1.0,0.3684210526315789,0.2947368421052632
which was introduced in Matthews (1975); it can be thought            (900) values for a given Nclust value from another. The results,0.0,0.7669172932330827,0.23308270676691734,21.0,7.0,0.0,0.30000000000000004
of as an equivalent to Pearson’s correlation coefficient for          are plotted versus the CI of the synthetic clusters. From panels a,0.0,0.7867647058823529,0.21323529411764708,21.0,6.0,0.0,0.28421052631578947
"binary classifiers. Unlike the TPR and PPV, the MCC also takes        to c the combinations N15 − N25 , N15 − N50 , and N25 − N50 are",0.0,0.7443609022556391,0.2556390977443609,28.0,5.0,0.0,0.30000000000000004
"the TNs into account. It is recommended when dealing with             shown, where a positive value means that the Nclust value on the",0.0,0.753731343283582,0.24626865671641796,22.0,7.0,0.0,0.2947368421052632
"imbalanced classes, as is our case.                                   left performed better than the value on the right, and vice versa",0.0,0.6222222222222222,0.37777777777777777,18.0,18.0,0.0,0.2894736842105263
"                                                                      for negative values. As can be seen, the differences are rather",70.0,0.39849624060150374,0.6015037593984962,11.0,1.0,0.3684210526315789,0.30000000000000004
To turn the problem into one of binary classification and to be       small and do not tend to change for different CI values. We thus,0.0,0.7761194029850746,0.22388059701492535,25.0,4.0,0.0,0.2947368421052632
"able to use the three metrics defined in the second group, we         decided to use the middle value Nclust = 25 for all the UPMASK",0.0,0.7575757575757576,0.24242424242424243,25.0,5.0,0.0,0.3052631578947368
"must first select a probability threshold that separates the stars    and pyUPMASK runs, as a reasonable number of default stars",0.0,0.828125,0.171875,20.0,3.0,0.0,0.3263157894736842
into the members and nonmembers classes. In KMM14 a single            per cluster for all the CI range.,0.0,0.7378640776699029,0.2621359223300971,17.0,7.0,0.0,0.45789473684210524
threshold of 90% was used. Since the choice of a threshold can,0.0,0.8225806451612904,0.17741935483870963,12.0,1.0,0.0,0.6736842105263158
"affect the results from these three metrics, we decided to use the",0.0,0.8333333333333334,0.16666666666666663,12.0,1.0,0.0,0.6526315789473685
following two different thresholds: 50% and 90%. This way we          12,0.0,0.7361111111111112,0.26388888888888884,11.0,6.0,0.0,0.6210526315789473
                                                                         We note that in KMM14 the statistical measures TPR and MMR are,73.0,0.37777777777777777,0.6222222222222222,12.0,1.0,0.38421052631578945,0.2894736842105263
"end up with the following nine metrics to test the performance        incorrectly defined. What the authors call “TPR” is the PPV, and what",0.0,0.7913669064748201,0.2086330935251799,23.0,5.0,0.0,0.2684210526315789
"of UPMASK and pyUPMASK: LSR, BSL, HMS, TPR5 , PPV5 ,                  they call “MMR” is the properly defined TPR.",0.0,0.6929824561403509,0.3070175438596491,19.0,10.0,0.0,0.4
"MCC5 , TPR9 , PPV9 , and MCC9 ; where the subindex 5 and 9            13",0.0,0.6388888888888888,0.36111111111111116,16.0,7.0,0.0,0.6210526315789473
"                                                                         It is 50 if we run the code using the UPMASKfile function, and 25 if",73.0,0.3829787234042553,0.6170212765957447,15.0,1.0,0.38421052631578945,0.2578947368421053
"indicate the 50% and 90% thresholds, respectively.                    we use the UPMASKdata function.",0.0,0.7029702970297029,0.29702970297029707,12.0,11.0,0.0,0.46842105263157896
"                                                                                                                  Article number, page 7 of 14",114.0,0.1619718309859155,0.8380281690140845,6.0,1.0,0.6,0.25263157894736843
avr_spaces,16.88235294117647,1.0,0.0,1.0,1.0,0.08885448916408668,0.9473684210526316
                                                   A&A proofs: manuscript no. pera_etal,51.0,0.367816091954023,0.632183908045977,5.0,1.0,0.26842105263157895,0.5421052631578948
"     Deciding how many times the outer loop should run is the       more details). We tested this modified version14 , which we refer",5.0,0.7593984962406015,0.24060150375939848,22.0,4.0,0.02631578947368421,0.30000000000000004
"other important parameter: a low number terminates the code be-     to as MST, using the same set of synthetic clusters and metrics",0.0,0.8091603053435115,0.19083969465648853,22.0,3.0,0.0,0.31052631578947365
fore it is able to present fully converged probability values and   employed so far. The code was executed with 25 runs of the,0.0,0.8095238095238095,0.19047619047619047,23.0,2.0,0.0,0.33684210526315794
a large number wastes processing time. We processed the same        outer loop and 15 stars per cluster; internal tests showed that,0.0,0.7938931297709924,0.20610687022900764,21.0,5.0,0.0,0.31052631578947365
set of 100 synthetic clusters with Nclust = 25 and analyzed when    this gave more adequate results than using 25.,0.0,0.8070175438596491,0.19298245614035092,20.0,3.0,0.0,0.4
each of the nine metrics converged to a stable value. The stabi-,0.0,0.828125,0.171875,12.0,1.0,0.0,0.6631578947368422
"lization point is defined as the outer loop run where the metric         The results of our six clustering methods, plus the MST",0.0,0.7734375,0.2265625,22.0,5.0,0.0,0.3263157894736842
"changes inside the ±0.025 range for five consecutive runs. The      method, versus UPMASK can be compressed into a single ma-",0.0,0.808,0.19199999999999995,20.0,4.0,0.0,0.3421052631578947
results are shown in Fig. 5 d. plot as a the convergence percentile trix plot as shown in Fig. 8. We show the X minus UPMASK,0.0,0.7983870967741935,0.2016129032258065,26.0,1.0,0.0,0.34736842105263155
"(i.e., the percentage of clusters that have converged) for each     percentage metric difference, where X represents each of the",0.0,0.828125,0.171875,19.0,3.0,0.0,0.3263157894736842
metric versus the outer loop run. Almost all the metrics reach      pyUPMASK clustering methods plus MST. This value is ob-,0.0,0.8048780487804879,0.19512195121951215,20.0,4.0,0.0,0.3526315789473684
"a convergence above 90% before the 25th outer loop run. The         tained subtracting the number of synthetic clusters, where",0.0,0.7936507936507936,0.2063492063492064,19.0,5.0,0.0,0.33684210526315794
"two exceptions are TPR9 and PPV9 , which still show a conver-       pyUPMASK/MST performed better than UPMASK, from the",0.0,0.7983193277310925,0.2016806722689075,19.0,4.0,0.0,0.37368421052631584
gence above 85% before the 25th run. Given these results we use     number of clusters where UPMASK showed a better perfor-,0.0,0.8048780487804879,0.19512195121951215,21.0,3.0,0.0,0.3526315789473684
"25 runs in the outer loop for all the UPMASK and pyUPMASK           mance, and taking the percentage. This difference ranges from",0.0,0.7674418604651163,0.2325581395348837,21.0,6.0,0.0,0.32105263157894737
"analyses with the obvious exceptions of the single-run methods      -100, which would indicate that UPMASK performed better on",0.0,0.8253968253968254,0.17460317460317465,18.0,4.0,0.0,0.33684210526315794
"described in Sect 2.2.1.                                            all 600 synthetic clusters, to 100, indicating that pyUPMASK",0.0,0.5703125,0.4296875,13.0,23.0,0.0,0.3263157894736842
     The PHOT set was processed using all the available photom-     (or MST) was the better performer for the 600 clusters. A value,5.0,0.7709923664122137,0.2290076335877863,22.0,3.0,0.02631578947368421,0.31052631578947365
"etry as input (V, B − V, U − B, V − I, J − H, H − K) but selecting  of 0 indicates that both methods performed better on an equal",0.0,0.751937984496124,0.24806201550387597,32.0,2.0,0.0,0.32105263157894737
"only the four principal dimensions after the principal compo-       number of cases. As can be seen, for the pyUPMASK meth-",0.0,0.7967479674796748,0.2032520325203252,20.0,4.0,0.0,0.3526315789473684
nent analysis dimensionality reduction. For the PM set we used      ods all the squares in the matrix are positive (the smallest be-,0.0,0.803030303030303,0.19696969696969702,22.0,4.0,0.0,0.3052631578947368
"the proper motions (µα , µδ), with no dimensionality reduction.     ing the PPV5 metric for the VOR method), which again shows",0.0,0.8095238095238095,0.19047619047619047,21.0,3.0,0.0,0.33684210526315794
"Proper motions are generally regarded as better cluster members     that pyUPMASK performed significantly better than UPMASK,",0.0,0.848,0.15200000000000002,16.0,3.0,0.0,0.3421052631578947
discriminators than photometry owing to the rounded shape of its    measured by any of the employed metrics. The advantage of the,0.0,0.8217054263565892,0.17829457364341084,21.0,3.0,0.0,0.32105263157894737
"distribution in contrast with the irregular shape of the sequence   MBK, KMS and GMM methods over the single-run methods is",0.0,0.8292682926829268,0.1707317073170732,20.0,2.0,0.0,0.3526315789473684
of a cluster in the photometric space.                              easier to see here compared to Figs. 6 and 7. The only exception,0.0,0.6363636363636364,0.36363636363636365,20.0,16.0,0.0,0.3052631578947368
"                                                                    is the TPR9 metric for which the VOR, KNN, and AGG meth-",68.0,0.3629032258064516,0.6370967741935484,12.0,1.0,0.35789473684210527,0.34736842105263155
                                                                    ods show a larger differential than the remaining multiple-runs,68.0,0.4198473282442748,0.5801526717557253,9.0,1.0,0.35789473684210527,0.31052631578947365
"4. Results                                                          methods; that is, more true members are classified as such. This",0.0,0.4772727272727273,0.5227272727272727,13.0,30.0,0.0,0.3052631578947368
"To ensure that the results are comparable between the               comes at the expense of the PPV9 metric, for which the MBK,",0.0,0.7322834645669292,0.26771653543307083,21.0,8.0,0.0,0.3315789473684211
"pyUPMASK and UPMASK runs, all the analyses were per-                KMS and GMM methods show much larger values; that is, fewer",0.0,0.7322834645669292,0.26771653543307083,20.0,9.0,0.0,0.3315789473684211
"formed on the same computer cluster. In what follows, the           field stars are incorrectly classified as members. Other than this,",0.0,0.7851851851851852,0.2148148148148148,20.0,6.0,0.0,0.2894736842105263
results are classified according to whether pyUPMASK or             there is no visible relation between any clustering method and a,0.0,0.7727272727272727,0.2272727272727273,19.0,7.0,0.0,0.3052631578947368
UPMASK performed better for a given metric and synthetic            given performance metric.,0.0,0.7634408602150538,0.23655913978494625,12.0,7.0,0.0,0.5105263157894737
cluster. We allow for a small range of ±0.005 to act as a “tie           The MST method shows a somewhat erratic behavior across,0.0,0.75,0.25,23.0,6.0,0.0,0.3263157894736842
zone” in which the two methods can be thought of as performing      the metrics. It performs worse than UPMASK for almost all of,0.0,0.7890625,0.2109375,23.0,4.0,0.0,0.3263157894736842
"equally well. In Appendix A we show the results of comparing        the clusters for several metrics (i.e., HMS, TPR5 , MCC9 and",0.0,0.78125,0.21875,22.0,5.0,0.0,0.3263157894736842
"pyUPMASK with the Bayesian method included in AsteCA.               TPR9 ) and better for a few others (e.g. LSR and BSL). Overall,",0.0,0.7404580152671756,0.2595419847328244,21.0,8.0,0.0,0.31052631578947365
These are not included here because the methods are not directly    the statistical performance of the MST method is worse than,0.0,0.8188976377952756,0.18110236220472442,21.0,3.0,0.0,0.3315789473684211
"comparable, as explained in the Appendix.                           UPMASK and pyUPMASK with any of the tested clustering",0.0,0.6694214876033058,0.3305785123966942,15.0,14.0,0.0,0.3631578947368421
"                                                                    methods. Notwithstanding, MST is faster than UPMASK (as we",68.0,0.3968253968253968,0.6031746031746033,9.0,1.0,0.35789473684210527,0.33684210526315794
     In Figs. 6 and 7 we show the metrics for the 320 and 280       show below) and outperforms all other methods in the LSR and,5.0,0.7265625,0.2734375,25.0,4.0,0.02631578947368421,0.3263157894736842
"synthetic clusters in the PHOT and PM datasets, respectively,       BSL metrics.",0.0,0.8,0.19999999999999996,11.0,4.0,0.0,0.5789473684210527
for each of the six clustering methods used in pyUPMASK.,0.0,0.8392857142857143,0.1607142857142857,10.0,1.0,0.0,0.7052631578947368
"The blue, yellow, and red bars depict the proportion of cases            In Fig. 9 we show the dependence with CI for the",0.0,0.7355371900826446,0.2644628099173554,22.0,7.0,0.0,0.3631578947368421
"for which pyUPMASK performed better, equally well, and for          pyUPMASK minus UPMASK difference for all the metrics, for",0.0,0.792,0.20799999999999996,18.0,6.0,0.0,0.3421052631578947
"which UPMASK performed better, respectively. It is easy to see      each clustering method. A positive value (green region) means",0.0,0.8217054263565892,0.17829457364341084,19.0,4.0,0.0,0.32105263157894737
"that, although with some variation across clustering methods,       that pyUPMASK performed better, while a negative value",0.0,0.8278688524590164,0.17213114754098358,16.0,4.0,0.0,0.35789473684210527
pyUPMASK has a better performance than UPMASK for all               (red region) means that it performed worse than UPMASK.,0.0,0.7479674796747967,0.2520325203252033,18.0,8.0,0.0,0.3526315789473684
"the methods and all the metrics, particularly for the PM dataset.   The PHOT and PM sets are shown with triangles and circles,",0.0,0.8174603174603174,0.18253968253968256,22.0,2.0,0.0,0.33684210526315794
This is an outstanding result that unmistakably shows the large     respectively. There is no apparent trend with CI for the results,0.0,0.8181818181818182,0.18181818181818177,21.0,3.0,0.0,0.3052631578947368
improvement brought by pyUPMASK. The three methods that             of any clustering method. What is clear is that pyUPMASK,0.0,0.7661290322580645,0.2338709677419355,18.0,7.0,0.0,0.34736842105263155
"apply multiple outer loop runs (MBK, KMS, GMM) show a               performs even better for the PM set as evidenced by the overall",0.0,0.732824427480916,0.26717557251908397,22.0,8.0,0.0,0.31052631578947365
"clear advantage over the remaining single-run methods, regard-      larger (more positive) differences, particularly for clusters with",0.0,0.8507462686567164,0.14925373134328357,16.0,4.0,0.0,0.2947368421052632
ing the proportion of cases for which pyUPMASK resulted in          large CI values. This is a very desirable result taking into,0.0,0.7734375,0.2265625,21.0,6.0,0.0,0.3263157894736842
larger metric values.                                               account that high quality proper motions are becoming more,0.0,0.5476190476190477,0.45238095238095233,12.0,24.0,0.0,0.33684210526315794
                                                                    accessible very fast.,68.0,0.21348314606741572,0.7865168539325843,3.0,1.0,0.35789473684210527,0.531578947368421
     In Cantat-Gaudin et al. (2018a) the authors used a modified,5.0,0.78125,0.21875,10.0,1.0,0.02631578947368421,0.6631578947368422
version of UPMASK to estimate membership probabilities                   We can further compress the results by combining each,0.0,0.7380952380952381,0.26190476190476186,16.0,10.0,0.0,0.33684210526315794
"for more than 1200 cataloged clusters. The modification was         metric into a single value, for each of the clustering methods",0.0,0.7923076923076923,0.20769230769230773,20.0,5.0,0.0,0.3157894736842105
"motivated by the need to increase the speed for processing          tested in pyUPMASK. That is, we take the 5400 results for",0.0,0.768,0.23199999999999998,21.0,6.0,0.0,0.3421052631578947
large numbers of clusters. This modification mainly consists in     each clustering method (600 synthetic clusters times nine,0.0,0.84,0.16000000000000003,17.0,3.0,0.0,0.3421052631578947
replacing the default KDE based method in the RFR block in,0.0,0.8275862068965517,0.1724137931034483,11.0,1.0,0.0,0.6947368421052631
                                                                    14,68.0,0.02857142857142857,0.9714285714285714,1.0,1.0,0.35789473684210527,0.631578947368421
UPMASK for a minimum spanning tree method (see article for             Thanks to Dr Cantat-Gaudin who shared the code with us.,0.0,0.753968253968254,0.24603174603174605,20.0,7.0,0.0,0.33684210526315794
"Article number, page 8 of 14",0.0,0.8214285714285714,0.1785714285714286,6.0,1.0,0.0,0.8526315789473684
avr_spaces,6.044117647058823,1.0,0.0,1.0,1.0,0.031811145510835914,0.9473684210526316
                                  M. S. Pera et al.: pyUPMASK: An improved unsupervised clustering algorithm,34.0,0.5925925925925926,0.40740740740740744,11.0,1.0,0.17894736842105263,0.43157894736842106
Fig. 6. Results for the 320 synthetic clusters in the PHOT dataset processed with the six clustering methods used in pyUPMASK vs. UPMASK. For,0.0,0.8368794326241135,0.16312056737588654,24.0,1.0,0.0,0.2578947368421053
"each metric, the blue and red bars represent the cases where pyUPMASK and UPMASK performed better, respectively. The yellow bars represent",0.0,0.855072463768116,0.14492753623188404,21.0,1.0,0.0,0.27368421052631575
cases in which both methods performed equally well.,0.0,0.8627450980392157,0.13725490196078427,8.0,1.0,0.0,0.7315789473684211
"Fig. 7. Same as Fig. 6 but for the 280 synthetic clusters in the PM dataset, exclusively.",0.0,0.8202247191011236,0.1797752808988764,17.0,1.0,0.0,0.531578947368421
Table 1. Aggregated results for all the metrics and all the synthetic clus-  metrics) and calculate the percentage at which pyUPMASK,0.0,0.8409090909090909,0.15909090909090906,21.0,2.0,0.0,0.3052631578947368
"ters, for the six pyUPMASK clustering methods used, as percentage of         outperformed UPMASK. The same process can be applied",0.0,0.7984496124031008,0.20155038759689925,19.0,5.0,0.0,0.32105263157894737
"results where pyUPMASK outperformed UPMASK, and vice versa, re-",0.0,0.873015873015873,0.12698412698412698,9.0,1.0,0.0,0.668421052631579
spectively. The missing percentage to add up to 100 corresponds to ties.,0.0,0.8472222222222222,0.1527777777777778,12.0,1.0,0.0,0.6210526315789473
                                                                             to the synthetic clusters for which UPMASK outperformed,77.0,0.36363636363636365,0.6363636363636364,8.0,1.0,0.4052631578947368,0.3052631578947368
"The second rows for each method show the minimum and maximum                 pyUPMASK to obtain a similar, inverted, percentage. The",0.0,0.7424242424242424,0.25757575757575757,19.0,9.0,0.0,0.3052631578947368
percentage values obtained for any single metric (shown in parenthe-         results are shown in Table 1. This table shows that even the,0.0,0.7883211678832117,0.21167883211678828,22.0,5.0,0.0,0.2789473684210526
"sis), for that method.                                                       worst pyUPMASK performer (VOR) gives better metrics than",0.0,0.5112781954887218,0.4887218045112782,12.0,28.0,0.0,0.30000000000000004
                                                                             UPMASK 66% of the times. The method with the highest,77.0,0.3333333333333333,0.6666666666666667,10.0,1.0,0.4052631578947368,0.32105263157894737
   Method             pyUPMASK                        UPMASK                 pyUPMASK percentage (GMM) outperforms UPMASK 83%,3.0,0.504,0.496,9.0,27.0,0.015789473684210527,0.3421052631578947
"                        min | max                      min | max             of the times, which is a massive advantage. The worst individual",24.0,0.48226950354609927,0.5177304964539007,17.0,18.0,0.12631578947368421,0.2578947368421053
   VOR                      66                            29                 metric result is obtained for TPR9 in the MBK method. Still the,3.0,0.42142857142857143,0.5785714285714285,15.0,34.0,0.015789473684210527,0.26315789473684215
"                  55 (BSL) | 78 (TPR9 )        13 (TPR9 ) | 42 (PPV5 )       value is larger than 50%, which means that the majority of the",18.0,0.60431654676259,0.39568345323741005,25.0,8.0,0.09473684210526316,0.2684210526315789
   KNN                      68                            27                 cases were better handled by pyUPMASK. On the other end,3.0,0.4015151515151515,0.5984848484848485,13.0,34.0,0.015789473684210527,0.3052631578947368
                  57 (BSL) | 85 (TPR9 )         8 (TPR9 ) | 40 (PPV5 )       of the analysis the best metric result is found for HMS in the,18.0,0.5899280575539568,0.41007194244604317,26.0,8.0,0.09473684210526316,0.2684210526315789
"   AGG                      72                            24                 GMM method, for which pyUPMASK manages to outperform",3.0,0.40310077519379844,0.5968992248062015,11.0,34.0,0.015789473684210527,0.32105263157894737
                  59 (BSL) | 90 (TPR9 )         4 (TPR9 ) | 38 (PPV5 )       UPMASK for virtually all of the cases.,18.0,0.5565217391304348,0.4434782608695652,20.0,8.0,0.09473684210526316,0.39473684210526316
   MBK                      77                            16,3.0,0.11666666666666667,0.8833333333333333,3.0,26.0,0.015789473684210527,0.6842105263157895
                51 (TPR9 ) | 90 (MCC5 )         8 (HMS) | 36 (TPR9 )             Another important aspect along with the performance,16.0,0.5833333333333334,0.41666666666666663,20.0,11.0,0.08421052631578947,0.3052631578947368
   KMS                      79                            15                 measured by the statistical metrics is the performance measured,3.0,0.44285714285714284,0.5571428571428572,12.0,34.0,0.015789473684210527,0.26315789473684215
                 66 (TPR9 ) | 88 (HMS)          8 (PPV9 ) | 22 (TPR9 )       in computing time. This is shown in Fig. 10 as a bar plot,17.0,0.5746268656716418,0.4253731343283582,26.0,9.0,0.08947368421052632,0.2947368421052632
   GMM                      83                            11                 normalized to the total time used by UPMASK to process the,3.0,0.4074074074074074,0.5925925925925926,14.0,34.0,0.015789473684210527,0.2894736842105263
                 74 (TPR9 ) | 93 (HMS)          5 (HMS) | 16 (LSR)           600 synthetic clusters. The numbers on top of the bars displays,17.0,0.5928571428571429,0.40714285714285714,22.0,11.0,0.08947368421052632,0.26315789473684215
                                                                             how many times faster each clustering method in pyUPMASK is,77.0,0.36764705882352944,0.6323529411764706,10.0,1.0,0.4052631578947368,0.28421052631578947
"                                                                                                                       Article number, page 9 of 14",119.0,0.1564625850340136,0.8435374149659864,6.0,1.0,0.6263157894736842,0.22631578947368425
avr_spaces,17.193548387096776,1.0,0.0,1.0,1.0,0.09049235993208829,0.9473684210526316
                                                    A&A proofs: manuscript no. pera_etal,52.0,0.36363636363636365,0.6363636363636364,5.0,1.0,0.2736842105263158,0.5368421052631579
"                                                                       makes it extremely efficient, thus making the pyUPMASK VOR",71.0,0.3875968992248062,0.6124031007751938,9.0,1.0,0.3736842105263158,0.32105263157894737
                                                                       method very efficient for large datasets.,71.0,0.32142857142857145,0.6785714285714286,6.0,1.0,0.3736842105263158,0.41052631578947374
                                                                           To test this we downloaded a large 6×6 deg region around,75.0,0.3511450381679389,0.6488549618320612,11.0,1.0,0.39473684210526316,0.31052631578947365
                                                                       the NGC2516 cluster from the Gaia second data release (Gaia,71.0,0.38461538461538464,0.6153846153846154,10.0,1.0,0.3736842105263158,0.3157894736842105
                                                                       Collaboration et al. 2018). The resulting field contains over,71.0,0.4015151515151515,0.5984848484848485,9.0,1.0,0.3736842105263158,0.3052631578947368
                                                                       420000 stars up to a maximum magnitude of G = 19 mag. This,71.0,0.35658914728682173,0.6434108527131783,13.0,1.0,0.3736842105263158,0.32105263157894737
                                                                       limit was imposed because beyond this value the photometric,71.0,0.3923076923076923,0.6076923076923078,9.0,1.0,0.3736842105263158,0.3157894736842105
                                                                       errors grow exponentially. The frame was processed with the six,71.0,0.40298507462686567,0.5970149253731343,10.0,1.0,0.3736842105263158,0.2947368421052632
"                                                                       tested pyUPMASK clustering methods and UPMASK, using",71.0,0.37398373983739835,0.6260162601626016,7.0,1.0,0.3736842105263158,0.3526315789473684
                                                                       proper motions and parallax as input data. We used 25 outer,71.0,0.3769230769230769,0.6230769230769231,11.0,1.0,0.3736842105263158,0.3157894736842105
"                                                                       loop iterations for all the methods, except of course for the",71.0,0.38636363636363635,0.6136363636363636,11.0,1.0,0.3736842105263158,0.3052631578947368
"                                                                       single-run methods, and a value of 25 for the parameter that",71.0,0.3816793893129771,0.6183206106870229,11.0,1.0,0.3736842105263158,0.31052631578947365
"                                                                       determines the number of elements per cluster (i.e., the default",71.0,0.4074074074074074,0.5925925925925926,10.0,1.0,0.3736842105263158,0.2894736842105263
                                                                       values for both parameters as explained in Sect. 3.3).,71.0,0.368,0.632,9.0,1.0,0.3736842105263158,0.3421052631578947
                                                                           Only three methods were able to complete the process:,75.0,0.3515625,0.6484375,9.0,1.0,0.39473684210526316,0.3263157894736842
"                                                                       VOR, KNN, and MBK. The methods AGG, KMS, and GMM",71.0,0.3277310924369748,0.6722689075630253,10.0,1.0,0.3736842105263158,0.37368421052631584
                                                                       failed owing to memory requirements as they attempted to,71.0,0.3779527559055118,0.6220472440944882,9.0,1.0,0.3736842105263158,0.3315789473684211
"                                                                       allocate arrays of ∼640 Gb, ∼31 Gb, and ∼31 Gb on memory,",71.0,0.359375,0.640625,12.0,1.0,0.3736842105263158,0.3263157894736842
                                                                       respectively. The UPMASK algorithm was not able to finish,71.0,0.3828125,0.6171875,9.0,1.0,0.3736842105263158,0.3263157894736842
                                                                       even the first iteration of the inner loop within the first iteration,71.0,0.4142857142857143,0.5857142857142856,12.0,1.0,0.3736842105263158,0.26315789473684215
"                                                                       of the outer loop after a full week of running, so it was halted.",71.0,0.38235294117647056,0.6176470588235294,14.0,1.0,0.3736842105263158,0.28421052631578947
"                                                                       The results of the VOR, KNN, and MBK methods can be seen",71.0,0.3543307086614173,0.6456692913385826,12.0,1.0,0.3736842105263158,0.3315789473684211
                                                                       in a color-magnitude diagram (CMD) in Fig. 11. We plotted the,71.0,0.38636363636363635,0.6136363636363636,11.0,1.0,0.3736842105263158,0.3052631578947368
Fig. 8. Matrix plot of the six pyUPMASK clustering methods plus        1500 stars with larger membership probabilities given by each,0.0,0.803030303030303,0.19696969696969702,20.0,5.0,0.0,0.3052631578947368
"MST, vs. the nine defined metrics for the 600 synthetic clusters. Each method, as this is the approximate number of cluster members",0.0,0.8396946564885496,0.16030534351145043,22.0,1.0,0.0,0.31052631578947365
square shows the percentage difference of the number of cases for      in the frame (given by a simple stellar density analysis). It is,0.0,0.8,0.19999999999999996,23.0,4.0,0.0,0.2894736842105263
"which pyUPMASK/MST performed better, minus the number for which        evident that the VOR method returns the most reasonable and",0.0,0.8076923076923077,0.1923076923076923,19.0,5.0,0.0,0.3157894736842105
"UPMASK performed better.                                               less contaminated CMD out of the three. Furthermore, this",0.0,0.5546875,0.4453125,12.0,24.0,0.0,0.3263157894736842
                                                                       method managed to process the cluster almost 4 and 40 times,71.0,0.3769230769230769,0.6230769230769231,11.0,1.0,0.3736842105263158,0.3157894736842105
"compared to UPMASK. We also show the time performance of               faster than KNN and MBK, respectively. It is worth noting that",0.0,0.7443609022556391,0.2556390977443609,21.0,8.0,0.0,0.30000000000000004
"the MST modification mentioned previously. The fastest method          on a personal computer, which has far less resources than a",0.0,0.7923076923076923,0.20769230769230773,19.0,6.0,0.0,0.3157894736842105
"is expectedly a single-run method, KNN, which performs 170             computational cluster, VOR was the only method that was able",0.0,0.7709923664122137,0.2290076335877863,19.0,7.0,0.0,0.31052631578947365
times faster than UPMASK. This is an enormous margin of                to run.,0.0,0.6666666666666666,0.33333333333333337,12.0,9.0,0.0,0.5894736842105264
"difference. Even the slowest method, GMM, is faster than",0.0,0.8571428571428571,0.1428571428571429,9.0,1.0,0.0,0.7052631578947368
UPMASK: this method manages to process the set of synthetic                A smaller field containing this same cluster was analyzed,0.0,0.75,0.25,19.0,9.0,0.0,0.3052631578947368
cluster employing almost 38% less time than UPMASK or 1.6              with UPMASK in Cantat-Gaudin et al. (2018a). The processed,0.0,0.7596899224806202,0.24031007751937983,19.0,8.0,0.0,0.32105263157894737
times faster. On average we can say that pyUPMASK using a              area contains only ∼1100 stars associated with this cluster up,0.0,0.7518796992481203,0.24812030075187974,21.0,8.0,0.0,0.30000000000000004
single-run method is over 100 times faster than UPMASK and             to a magnitude of G=18 mag. The analysis done in this work,0.0,0.7441860465116279,0.2558139534883721,22.0,7.0,0.0,0.32105263157894737
is more than 3 times faster for the multiple run methods.              resulted in less than 800 stars with membership probabilities,0.0,0.7575757575757576,0.24242424242424243,20.0,8.0,0.0,0.3052631578947368
"                                                                       (MPs) above 0.5 and ∼100 stars with MPs> 0.9. In contrast,",71.0,0.37209302325581395,0.627906976744186,11.0,1.0,0.3736842105263158,0.32105263157894737
"     The choice between which clustering method to employ in           using the same magnitude cut, we are able to obtain with",5.0,0.7322834645669292,0.26771653543307083,20.0,6.0,0.02631578947368421,0.3315789473684211
pyUPMASK then depends on the specific requirements of the              the VOR method on our very large field over 1700 stars with,0.0,0.7461538461538462,0.25384615384615383,21.0,8.0,0.0,0.3157894736842105
analysis. If the absolute best performance measured by a classi-       MPs> 0.99 tracing a well-defined sequence. The advantage,0.0,0.8188976377952756,0.18110236220472442,18.0,4.0,0.0,0.3315789473684211
"fication metric is sought after, then clearly GMM is the method        of studying a cluster using almost all of its members versus",0.0,0.7862595419847328,0.2137404580152672,22.0,5.0,0.0,0.31052631578947365
to chose (with the advantage of being faster than UPMASK). If          using less than 10% of the members (comparing the large MPs,0.0,0.7692307692307693,0.23076923076923073,22.0,6.0,0.0,0.3157894736842105
"we can trade some performance for a faster process, then KMS           subsets), is obvious.",0.0,0.75,0.25,14.0,6.0,0.0,0.5157894736842106
or MBK can be used. And if we are willing to trade even more,0.0,0.7833333333333333,0.21666666666666667,14.0,1.0,0.0,0.6842105263157895
"classification performance, while still performing much better             The VOR method is thus the only one that was able to pro-",0.0,0.7651515151515151,0.23484848484848486,20.0,7.0,0.0,0.3052631578947368
"than UPMASK, then VOR, KNN, or AGG are by far the fastest              duce quality results for this very large dataset, and it did so while",0.0,0.7357142857142858,0.26428571428571423,25.0,8.0,0.0,0.26315789473684215
approaches.                                                            using the least amount of processing time by a wide margin.,0.0,0.46153846153846156,0.5384615384615384,12.0,31.0,0.0,0.3157894736842105
"     Finally, we consider the issue of computational resources re-     5. Conclusions",5.0,0.7764705882352941,0.22352941176470587,11.0,3.0,0.02631578947368421,0.5526315789473684
quirements. We found that for very large input data files memory,0.0,0.84375,0.15625,11.0,1.0,0.0,0.6631578947368422
and processing power requirements can be too much for most             Since its development in KMM14 the UPMASK code has been,0.0,0.753968253968254,0.24603174603174605,20.0,7.0,0.0,0.33684210526315794
methods to handle. Although the VOR clustering method is the           used to analyze thousands of clusters. This is because it is a very,0.0,0.7681159420289855,0.23188405797101452,23.0,6.0,0.0,0.27368421052631575
"worst performer out of the six tested methods (measured by clas-       smart, general, and efficient unsupervised method, that requires",0.0,0.8222222222222222,0.1777777777777778,19.0,4.0,0.0,0.2894736842105263
"sification metrics), it has an advantage compared to all the others,   no prior knowledge about the observed field. In this work we",0.0,0.8244274809160306,0.17557251908396942,22.0,2.0,0.0,0.31052631578947365
"including UPMASK, when it comes to analyzing large files. To           introduced pyUPMASK, a tool based on the general UPMASK",0.0,0.7777777777777778,0.2222222222222222,19.0,6.0,0.0,0.33684210526315794
"obtain the Voronoi diagram of an N-dimensional set of points,          algorithm with several added enhancements. The primary aim",0.0,0.7984496124031008,0.20155038759689925,18.0,6.0,0.0,0.32105263157894737
the Python scipy package relies on the Qhull library (Barber           of pyUPMASK is the assignment of membership probabilities,0.0,0.7890625,0.2109375,18.0,6.0,0.0,0.3263157894736842
et al. 1996)15 . This library is written in the C language which       to cluster stars observed in a frame contaminated by field stars.,0.0,0.7867647058823529,0.21323529411764708,24.0,4.0,0.0,0.28421052631578947
                                                                       We tested our code extensively using 600 synthetic clusters af-,71.0,0.40298507462686567,0.5970149253731343,10.0,1.0,0.3736842105263158,0.2947368421052632
15,0.0,1.0,0.0,1.0,1.0,0.0,0.9894736842105263
   http://www.qhull.org/                                               fected by a large range of contamination. Six performance met-,3.0,0.556390977443609,0.443609022556391,11.0,24.0,0.015789473684210527,0.30000000000000004
"Article number, page 10 of 14",0.0,0.8275862068965517,0.1724137931034483,6.0,1.0,0.0,0.8473684210526315
avr_spaces,29.07575757575757,1.0,0.0,1.0,1.0,0.15303030303030302,0.9473684210526316
                                     M. S. Pera et al.: pyUPMASK: An improved unsupervised clustering algorithm,37.0,0.5765765765765766,0.42342342342342343,11.0,1.0,0.19473684210526315,0.4157894736842105
"Fig. 9. Differences between pyUPMASK vs. UPMASK results for all the metrics combined, vs. the CI (shown as a logarithm). Each clustering",0.0,0.8455882352941176,0.15441176470588236,22.0,1.0,0.0,0.28421052631578947
"method is shown separately, as are the PHOT and PM sets using blue triangles and black circles, respectively. The red and green regions correspond",0.0,0.8424657534246576,0.15753424657534243,24.0,1.0,0.0,0.2315789473684211
"to the regions for which pyUPMASK gives worse and better results than UPMASK, respectively.",0.0,0.8571428571428571,0.1428571428571429,14.0,1.0,0.0,0.5210526315789474
                                                                               //github.com/cran/hmeasure) R package. The authors would like to thank,79.0,0.4161073825503356,0.5838926174496644,9.0,1.0,0.41578947368421054,0.21578947368421053
                                                                               Dr Cantat-Gaudin for sharing the code used in Cantat-Gaudin et al. (2018a).,79.0,0.4155844155844156,0.5844155844155844,12.0,1.0,0.41578947368421054,0.18947368421052635
"                                                                               M.S.P., G.I.P., and R.A.V. acknowledge the financial support from CONICET",79.0,0.42105263157894735,0.5789473684210527,10.0,1.0,0.41578947368421054,0.19999999999999996
                                                                               (PIP317) and the UNLP (PID-G148 project). AM acknowledges support from,79.0,0.40939597315436244,0.5906040268456376,10.0,1.0,0.41578947368421054,0.21578947368421053
                                                                               the Portuguese Fundação para a Ciência e a Tecnologia (FCT) through the Strate-,79.0,0.4240506329113924,0.5759493670886076,13.0,1.0,0.41578947368421054,0.16842105263157892
                                                                               gic Programme UID/FIS/00099/2019 for CENTRA. This research has made use,79.0,0.41333333333333333,0.5866666666666667,10.0,1.0,0.41578947368421054,0.21052631578947367
                                                                               of NASA’s Astrophysics Data System. This research made use of the Python lan-,79.0,0.4166666666666667,0.5833333333333333,13.0,1.0,0.41578947368421054,0.17894736842105263
                                                                               guage (van Rossum 1995) and the following packages: NumPy17 (Van Der Walt,79.0,0.40789473684210525,0.5921052631578947,12.0,1.0,0.41578947368421054,0.19999999999999996
"                                                                               et al. 2011); SciPy18 (Jones et al. 2001); Astropy19 , a community-developed",79.0,0.41935483870967744,0.5806451612903225,12.0,1.0,0.41578947368421054,0.1842105263157895
                                                                               core Python package for Astronomy (Astropy Collaboration et al. 2013; Price-,79.0,0.4258064516129032,0.5741935483870968,11.0,1.0,0.41578947368421054,0.1842105263157895
                                                                               Whelan et al. 2018); scikit-learn20 (Pedregosa et al. 2011b); matplotlib21 (Hunter,79.0,0.4472049689440994,0.5527950310559007,11.0,1.0,0.41578947368421054,0.15263157894736845
                                                                               et al. 2007). This work has made use of data from the European Space Agency,79.0,0.3961038961038961,0.6038961038961039,15.0,1.0,0.41578947368421054,0.18947368421052635
"                                                                               (ESA) mission Gaia (https://www.cosmos.esa.int/gaia), processed by",79.0,0.4206896551724138,0.5793103448275863,6.0,1.0,0.41578947368421054,0.23684210526315785
"                                                                               the Gaia Data Processing and Analysis Consortium (DPAC, https://www.",79.0,0.40816326530612246,0.5918367346938775,9.0,1.0,0.41578947368421054,0.22631578947368425
                                                                               cosmos.esa.int/web/gaia/dpac/consortium). Funding for the DPAC has,79.0,0.4206896551724138,0.5793103448275863,6.0,1.0,0.41578947368421054,0.23684210526315785
"                                                                               been provided by national institutions, in particular the institutions participating",79.0,0.4601226993865031,0.5398773006134969,10.0,1.0,0.41578947368421054,0.14210526315789473
                                                                               in the Gaia Multilateral Agreement.,79.0,0.2719298245614035,0.7280701754385965,5.0,1.0,0.41578947368421054,0.4
Fig. 10. Amount of time employed in processing the 600 synthetic clus-,0.0,0.8428571428571429,0.15714285714285714,12.0,1.0,0.0,0.631578947368421
                                                                               References,79.0,0.11235955056179775,0.8876404494382022,1.0,1.0,0.41578947368421054,0.531578947368421
"ters by each pyUPMASK method (blue bars), the MST method (or-                  Astropy Collaboration, Robitaille, T. P., Tollerud, E. J., et al. 2013, A&A, 558,",0.0,0.75,0.25,24.0,10.0,0.0,0.1578947368421053
"ange bar), and UPMASK (red bar). The bars are normalized so that                   A33",0.0,0.6511627906976745,0.34883720930232553,13.0,10.0,0.0,0.5473684210526315
"UPMASK corresponds to a total value of 1.                                      Baddeley, A., Rubak, E., & Turner, R. 2015, Spatial Point Patterns: Methodology",0.0,0.6455696202531646,0.35443037974683544,20.0,20.0,0.0,0.16842105263157892
"                                                                                   and Applications with R, Chapman & Hall/CRC Interdisciplinary Statistics",83.0,0.4129032258064516,0.5870967741935484,9.0,1.0,0.4368421052631579,0.1842105263157895
                                                                                   (CRC Press),83.0,0.10638297872340426,0.8936170212765957,2.0,1.0,0.4368421052631579,0.5052631578947369
"                                                                               Balaguer-Núñez, L., López del Fresno, M., Solano, E., et al. 2020, MNRAS, 492,",79.0,0.42038216560509556,0.5796178343949044,13.0,1.0,0.41578947368421054,0.17368421052631577
"rics were employed, three of which were in two different config-                   5811",0.0,0.6666666666666666,0.33333333333333337,12.0,10.0,0.0,0.5421052631578948
"urations, to ensure sufficient coverage when assessing statistical             Barber, C. B., Dobkin, D. P., & Huhdanpaa, H. 1996, ACM TRANSACTIONS",0.0,0.7891156462585034,0.2108843537414966,20.0,7.0,0.0,0.22631578947368425
"classification. The results from six different clustering methods                  ON MATHEMATICAL SOFTWARE, 22, 469",0.0,0.75,0.25,13.0,10.0,0.0,0.3894736842105263
"in pyUPMASK were compared to those from UPMASK. Under                          Baxter, R. A. 2010, Mixture Model, ed. C. Sammut & G. I. Webb (Boston, MA:",0.0,0.6862745098039216,0.3137254901960784,24.0,14.0,0.0,0.1947368421052632
"the conditions established for the analysis, the pyUPMASK tool                     Springer US), 680–682",0.0,0.7019230769230769,0.29807692307692313,12.0,11.0,0.0,0.4526315789473684
"                                                                               Brier, G. W. 1950, Monthly Weather Review, 78, 1",79.0,0.31496062992125984,0.6850393700787402,9.0,1.0,0.41578947368421054,0.3315789473684211
"proved to clearly outperform UPMASK while still managing to                    Cabrera-Cano, J. & Alfaro, E. J. 1990, A&A, 235, 94",0.0,0.7153846153846154,0.2846153846153846,19.0,11.0,0.0,0.3157894736842105
"be faster (and, for the single-run methods, extremely faster).                 Cantat-Gaudin, T., Jordi, C., Vallenari, A., et al. 2018a, A&A, 618, A93",0.0,0.7615894039735099,0.23841059602649006,21.0,9.0,0.0,0.20526315789473681
"     This new tool is thus highly configurable (around a dozen                 Cantat-Gaudin, T., Jordi, C., Wright, N. J., et al. 2019, A&A, 626, A17",5.0,0.7133333333333334,0.2866666666666666,23.0,9.0,0.02631578947368421,0.21052631578947367
"clustering algorithms supported), fast, and an excellent per-                  Cantat-Gaudin, T., Vallenari, A., Sordo, R., et al. 2018b, A&A, 615, A49",0.0,0.7615894039735099,0.23841059602649006,20.0,10.0,0.0,0.20526315789473681
"former measured by several metrics. The pyUPMASK algorithm                     Carrera, R., Pasquato, M., Vallenari, A., et al. 2019, A&A, 627, A119",0.0,0.7364864864864865,0.2635135135135135,20.0,11.0,0.0,0.2210526315789474
"                                                                               Dempster, A. P., Laird, N. M., & Rubin, D. B. 1977, Journal of the Royal Statis-",79.0,0.4088050314465409,0.5911949685534591,16.0,1.0,0.41578947368421054,0.16315789473684206
"is fully written in Python and is made available for its use under                 tical Society: Series B (Methodological), 39, 1",0.0,0.7307692307692307,0.2692307692307693,20.0,9.0,0.0,0.3157894736842105
a GPL v3 general public license16 .,0.0,0.8285714285714286,0.17142857142857137,7.0,1.0,0.0,0.8157894736842105
                                                                               17,79.0,0.024691358024691357,0.9753086419753086,1.0,1.0,0.41578947368421054,0.5736842105263158
"Acknowledgements. The authors would like to thank the anonymous referee, for       http://www.numpy.org/",0.0,0.8365384615384616,0.16346153846153844,12.0,4.0,0.0,0.4526315789473684
                                                                               18,79.0,0.024691358024691357,0.9753086419753086,1.0,1.0,0.41578947368421054,0.5736842105263158
their helpful suggestions and corrections to the manuscript. The authors would     http://www.scipy.org/,0.0,0.8557692307692307,0.14423076923076927,12.0,3.0,0.0,0.4526315789473684
                                                                               19,79.0,0.024691358024691357,0.9753086419753086,1.0,1.0,0.41578947368421054,0.5736842105263158
like to thank Dr Anagnostopoulos for his help with the hmeasure (https:            http://www.astropy.org/,0.0,0.7830188679245284,0.21698113207547165,13.0,7.0,0.0,0.4421052631578948
                                                                               20,79.0,0.024691358024691357,0.9753086419753086,1.0,1.0,0.41578947368421054,0.5736842105263158
                                                                                   http://scikit-learn.org/,83.0,0.22429906542056074,0.7757009345794392,1.0,1.0,0.4368421052631579,0.4368421052631579
16                                                                             21,0.0,0.04938271604938271,0.9506172839506173,2.0,39.0,0.0,0.5736842105263158
   https://www.gnu.org/copyleft/gpl.html                                           http://matplotlib.org/,3.0,0.5619047619047619,0.4380952380952381,2.0,22.0,0.015789473684210527,0.4473684210526315
"                                                                                                                                Article number, page 11 of 14",128.0,0.15286624203821655,0.8471337579617835,6.0,1.0,0.6736842105263158,0.17368421052631577
avr_spaces,43.58181818181818,1.0,0.0,1.0,1.0,0.229377990430622,0.9473684210526316
                                                                A&A proofs: manuscript no. pera_etal,64.0,0.32,0.6799999999999999,5.0,1.0,0.3368421052631579,0.4736842105263158
"Fig. 11. Results for the NGC2516 cluster by the VOR (left), KNN (center), and MBK (right) methods. Estimated members are shown as green",0.0,0.837037037037037,0.16296296296296298,23.0,1.0,0.0,0.2894736842105263
circles; the field stars are shown as gray dots.,0.0,0.8333333333333334,0.16666666666666663,9.0,1.0,0.0,0.7473684210526316
"Dixon, P. M. 2014, Ripley’s K Function (American Cancer Society)                    van Rossum, G. 1995, Python tutorial, Report CS-R9526, pub-CWI, pub-",0.0,0.75,0.25,20.0,11.0,0.0,0.19999999999999996
"Gaia Collaboration, Brown, A. G. A., Vallenari, A., et al. 2018, A&A, 616, A1          CWI:adr",0.0,0.7553191489361702,0.24468085106382975,15.0,6.0,0.0,0.5052631578947369
"Gaia Collaboration, Brown, A. G. A., Vallenari, A., et al. 2020, arXiv e-prints,    Vasilevskis, S., Klemola, A., & Preston, G. 1958, The Astronomical Journal, 63,",0.0,0.8343558282208589,0.16564417177914115,25.0,3.0,0.0,0.14210526315789473
   arXiv:2012.01533                                                                    387,3.0,0.2111111111111111,0.7888888888888889,2.0,35.0,0.015789473684210527,0.5263157894736843
"Gaia Collaboration, Prusti, T., de Bruijne, J. H. J., et al. 2016, A&A, 595, A1     Voronoi, G. 1908, Journal für die reine und angewandte Mathematik, 1908, 97",0.0,0.8113207547169812,0.18867924528301883,27.0,3.0,0.0,0.16315789473684206
"Good, I. J. 1952, Journal of the Royal Statistical Society. Series B (Methodolog-   Yontan, T., Bilir, S., Bostancı, Z. F., et al. 2019, Astrophysics and Space Science,",0.0,0.8333333333333334,0.16666666666666663,27.0,2.0,0.0,0.11578947368421055
"   ical), 14, 107                                                                      364",3.0,0.16666666666666666,0.8333333333333334,4.0,36.0,0.015789473684210527,0.5263157894736843
"Hand, D. & Anagnostopoulos, C. 2014, Pattern Recognition Letters, 40, 41            Zepeda-Mendoza, M. L. & Resendis-Antonio, O. 2013, Hierarchical Agglomer-",0.0,0.8089171974522293,0.19108280254777066,20.0,7.0,0.0,0.17368421052631577
"Hand, D. J. 2009, Machine Learning, 77, 103                                            ative Clustering, ed. W. Dubitzky, O. Wolkenhauer, K.-H. Cho, & H. Yokota",0.0,0.6125,0.38749999999999996,20.0,23.0,0.0,0.1578947368421053
"Hernández-Orallo, J., Flach, P., & Ferri, C. 2012, Journal of Machine Learning         (New York, NY: Springer New York), 886–887",0.0,0.7984496124031008,0.20155038759689925,19.0,5.0,0.0,0.32105263157894737
"   Research, 13, 2813",3.0,0.7619047619047619,0.23809523809523814,3.0,1.0,0.015789473684210527,0.8894736842105263
"Hunter, J. D. et al. 2007, Computing in science and engineering, 9, 90",0.0,0.8285714285714286,0.17142857142857137,13.0,1.0,0.0,0.631578947368421
"Javakhishvili, G., Kukhianidze, V., Todua, M., & Inasaridze, R. 2006, Astronomy",0.0,0.8734177215189873,0.12658227848101267,11.0,1.0,0.0,0.5842105263157895
"   & Astrophysics, 447, 915",3.0,0.7777777777777778,0.2222222222222222,4.0,1.0,0.015789473684210527,0.8578947368421053
"Jones, B. F. & Walker, M. F. 1988, AJ, 95, 1755",0.0,0.7872340425531915,0.21276595744680848,11.0,1.0,0.0,0.7526315789473684
"Jones, E., Oliphant, T., Peterson, P., et al. 2001, SciPy: Open source scientific",0.0,0.8518518518518519,0.14814814814814814,13.0,1.0,0.0,0.5736842105263158
"   tools for Python, [Online; accessed 2016-06-21]",3.0,0.84,0.16000000000000003,6.0,1.0,0.015789473684210527,0.736842105263158
"Krone-Martins, A. & Moitinho, A. 2014, A&A, 561, A57",0.0,0.8461538461538461,0.15384615384615385,9.0,1.0,0.0,0.7263157894736842
"Lagache, T., Lang, G., Sauvonnet, N., & Olivo-Marin, J.-C. 2013, PLoS ONE,",0.0,0.8513513513513513,0.14864864864864868,12.0,1.0,0.0,0.6105263157894737
"   8, e80914",3.0,0.6666666666666666,0.33333333333333337,2.0,1.0,0.015789473684210527,0.9368421052631579
"Lobo, J. M., Jiménez-Valverde, A., & Real, R. 2008, Global Ecology and Bio-",0.0,0.84,0.16000000000000003,13.0,1.0,0.0,0.6052631578947368
"   geography, 17, 145",3.0,0.7619047619047619,0.23809523809523814,3.0,1.0,0.015789473684210527,0.8894736842105263
"MacQueen, J. 1967, in Proceedings of the Fifth Berkeley Symposium on Mathe-",0.0,0.8533333333333334,0.1466666666666666,12.0,1.0,0.0,0.6052631578947368
"   matical Statistics and Probability, Volume 1: Statistics (Berkeley, Calif.: Uni-",3.0,0.8554216867469879,0.14457831325301207,10.0,1.0,0.015789473684210527,0.5631578947368421
"   versity of California Press), 281–297",3.0,0.825,0.17500000000000004,5.0,1.0,0.015789473684210527,0.7894736842105263
"Marcon, E., Traissac, S., & Lang, G. 2013, ISRN Ecology, 2013, 1",0.0,0.828125,0.171875,12.0,1.0,0.0,0.6631578947368422
"Matthews, B. 1975, Biochimica et Biophysica Acta (BBA) - Protein Structure,",0.0,0.8666666666666667,0.1333333333333333,11.0,1.0,0.0,0.6052631578947368
"   405, 442",3.0,0.6363636363636364,0.36363636363636365,2.0,1.0,0.015789473684210527,0.9421052631578948
"Merkle, E. C. & Steyvers, M. 2013, Decision Analysis, 10, 292",0.0,0.8360655737704918,0.16393442622950816,11.0,1.0,0.0,0.6789473684210526
"Momcheva, I. & Tollerud, E. 2015, arXiv e-prints, arXiv:1507.03989",0.0,0.8787878787878788,0.12121212121212122,9.0,1.0,0.0,0.6526315789473685
"Parker, C. 2011, in 2011 IEEE 11th International Conference on Data Mining",0.0,0.8513513513513513,0.14864864864864868,12.0,1.0,0.0,0.6105263157894737
   (IEEE),3.0,0.6666666666666666,0.33333333333333337,1.0,1.0,0.015789473684210527,0.9526315789473684
"Pedregosa, F., Varoquaux, G., Gramfort, A., et al. 2011a, Journal of Machine",0.0,0.8552631578947368,0.14473684210526316,12.0,1.0,0.0,0.6
"   Learning Research, 12, 2825",3.0,0.8,0.19999999999999996,4.0,1.0,0.015789473684210527,0.8421052631578947
"Pedregosa, F., Varoquaux, G., Gramfort, A., et al. 2011b, Journal of Machine",0.0,0.8552631578947368,0.14473684210526316,12.0,1.0,0.0,0.6
"   Learning Research, 12, 2825",3.0,0.8,0.19999999999999996,4.0,1.0,0.015789473684210527,0.8421052631578947
"Perren, G. I., Vázquez, R. A., & Piatti, A. E. 2015, A&A, 576, A6",0.0,0.8,0.19999999999999996,14.0,1.0,0.0,0.6578947368421053
"Price-Whelan, A. M., Sipőcz, B. M., Günther, H. M., et al. 2018, AJ, 156, 123",0.0,0.8205128205128205,0.17948717948717952,15.0,1.0,0.0,0.5894736842105264
"Ripley, B. D. 1976, Journal of Applied Probability, 13, 255–266",0.0,0.8571428571428571,0.1428571428571429,10.0,1.0,0.0,0.668421052631579
"Ripley, B. D. 1979, Journal of the Royal Statistical Society. Series B (Method-",0.0,0.8481012658227848,0.15189873417721522,13.0,1.0,0.0,0.5842105263157895
"   ological), 41, 368",3.0,0.7619047619047619,0.23809523809523814,3.0,1.0,0.015789473684210527,0.8894736842105263
"Rodriguez, A. & Laio, A. 2014, Science, 344, 1492",0.0,0.8367346938775511,0.16326530612244894,9.0,1.0,0.0,0.7421052631578947
"Sanders, W. L. 1971, A&A, 14, 226",0.0,0.8181818181818182,0.18181818181818177,7.0,1.0,0.0,0.8263157894736842
"Sculley, D. 2010, in Proceedings of the 19th International Conference on World",0.0,0.8589743589743589,0.14102564102564108,12.0,1.0,0.0,0.5894736842105264
"   Wide Web, WWW ’10 (New York, NY, USA: Association for Computing",3.0,0.803030303030303,0.19696969696969702,11.0,1.0,0.015789473684210527,0.6526315789473685
"   Machinery), 1177–1178",3.0,0.8333333333333334,0.16666666666666663,2.0,1.0,0.015789473684210527,0.8736842105263158
"Streib, K. & Davis, J. W. 2011, in CVPR 2011, 2305–2312",0.0,0.8181818181818182,0.18181818181818177,11.0,1.0,0.0,0.7105263157894737
"Tollerud, E. J., Smith, A. M., Price-Whelan, A., et al. 2019, Bulletin of the Amer-",0.0,0.8313253012048193,0.1686746987951807,15.0,1.0,0.0,0.5631578947368421
"   ican Astronomical Society, 51, 180",3.0,0.8108108108108109,0.18918918918918914,5.0,1.0,0.015789473684210527,0.8052631578947369
"Van Der Walt, S., Colbert, S. C., & Varoquaux, G. 2011, Computing in Science",0.0,0.8289473684210527,0.17105263157894735,14.0,1.0,0.0,0.6
"   & Engineering, 13, 22",3.0,0.75,0.25,4.0,1.0,0.015789473684210527,0.8736842105263158
"Article number, page 12 of 14",0.0,0.8275862068965517,0.1724137931034483,6.0,1.0,0.0,0.8473684210526315
avr_spaces,2.107142857142857,1.0,0.0,1.0,1.0,0.011090225563909775,0.9473684210526316
                                M. S. Pera et al.: pyUPMASK: An improved unsupervised clustering algorithm,32.0,0.6037735849056604,0.39622641509433965,11.0,1.0,0.16842105263157894,0.4421052631578948
Appendix A: pyUPMASK versus ASteCA results,0.0,0.8809523809523809,0.11904761904761907,6.0,1.0,0.0,0.7789473684210526
We present a comparison between the membership probability,0.0,0.8793103448275862,0.12068965517241381,8.0,1.0,0.0,0.6947368421052631
estimation algorithm included in ASteCA and pyUPMASK. It is,0.0,0.864406779661017,0.13559322033898302,9.0,1.0,0.0,0.6894736842105262
worth noting that ASteCA is a complete package for processing,0.0,0.8524590163934426,0.14754098360655743,10.0,1.0,0.0,0.6789473684210526
stellar clusters that includes a Bayesian membership estimation,0.0,0.8888888888888888,0.11111111111111116,8.0,1.0,0.0,0.668421052631579
"method. This method, which has not changed since the Perren",0.0,0.847457627118644,0.15254237288135597,10.0,1.0,0.0,0.6894736842105262
"et al. (2015) article was published, is based on comparing the",0.0,0.8387096774193549,0.16129032258064513,11.0,1.0,0.0,0.6736842105263158
distributions of field stars and stars within the cluster region in,0.0,0.8507462686567164,0.14925373134328357,11.0,1.0,0.0,0.6473684210526316
"whatever data space the user decides to use (photometric, proper",0.0,0.859375,0.140625,10.0,1.0,0.0,0.6631578947368422
"motions, parallax, or any combination). The cluster region is de-",0.0,0.8615384615384616,0.1384615384615384,10.0,1.0,0.0,0.6578947368421053
fined by the center coordinates and radius values estimated by,0.0,0.8548387096774194,0.14516129032258063,10.0,1.0,0.0,0.6736842105263158
separate methods in ASteCA that were applied previous to the,0.0,0.85,0.15000000000000002,10.0,1.0,0.0,0.6842105263157895
Bayesian membership method. The pyUPMASK method (simi-,0.0,0.8888888888888888,0.11111111111111116,7.0,1.0,0.0,0.7157894736842105
"larly UPMASK), on the other hand, is a method for estimating",0.0,0.8333333333333334,0.16666666666666663,11.0,1.0,0.0,0.6842105263157895
"membership probabilities. That is, it represents just a portion of",0.0,0.8636363636363636,0.13636363636363635,10.0,1.0,0.0,0.6526315789473685
what the ASteCA package comprises.,0.0,0.8823529411764706,0.11764705882352944,5.0,1.0,0.0,0.8210526315789474
     The reason for not including this comparison in the main ar-,5.0,0.7692307692307693,0.23076923076923073,11.0,1.0,0.02631578947368421,0.6578947368421053
ticle is that the Bayesian method in ASteCA and pyUPMASK are,0.0,0.8333333333333334,0.16666666666666663,11.0,1.0,0.0,0.6842105263157895
"not directly comparable. Unlike UPMASK and pyUPMASK,",0.0,0.8846153846153846,0.11538461538461542,7.0,1.0,0.0,0.7263157894736842
"which are unsupervised methods, the membership method",0.0,0.8867924528301887,0.1132075471698113,7.0,1.0,0.0,0.7210526315789474
included in ASteCA is supervised because it requires an a,0.0,0.8421052631578947,0.1578947368421053,10.0,1.0,0.0,0.7
"priori separation of classes. That is: the field stars, identified as",0.0,0.855072463768116,0.14492753623188404,11.0,1.0,0.0,0.6368421052631579
"those stars located in the field region, and the possible cluster",0.0,0.8461538461538461,0.15384615384615385,11.0,1.0,0.0,0.6578947368421053
"members, identified as those stars located in the cluster region,",0.0,0.8615384615384616,0.1384615384615384,10.0,1.0,0.0,0.6578947368421053
must be segregated before the membership method can be,0.0,0.8518518518518519,0.14814814814814814,9.0,1.0,0.0,0.7157894736842105
"applied. Hence, the membership probabilities obtained with the",0.0,0.8870967741935484,0.11290322580645162,8.0,1.0,0.0,0.6736842105263158
Bayesian method in ASteCA are a reflection not only of the,0.0,0.8275862068965517,0.1724137931034483,11.0,1.0,0.0,0.6947368421052631
"method itself, but also of the separate methods used to estimate",0.0,0.84375,0.15625,11.0,1.0,0.0,0.6631578947368422
the center and radius values.,0.0,0.8620689655172413,0.13793103448275867,5.0,1.0,0.0,0.8473684210526315
     The ASteCA algorithm was thus applied on both datasets,5.0,0.7796610169491526,0.22033898305084743,9.0,1.0,0.02631578947368421,0.6894736842105262
"(PHOT and PM), allowing it to automatically estimate the center",0.0,0.8571428571428571,0.1428571428571429,10.0,1.0,0.0,0.668421052631579
coordinates and radius value of the synthetic cluster. As shown,0.0,0.8571428571428571,0.1428571428571429,10.0,1.0,0.0,0.668421052631579
"in Figs A.1 and A.2, pyUPMASK performs better than ASteCA",0.0,0.8421052631578947,0.1578947368421053,10.0,1.0,0.0,0.7
"for both datasets, particularly for the PHOT synthetic clusters.",0.0,0.875,0.125,9.0,1.0,0.0,0.6631578947368422
We emphasize again that these results are not directly compara-,0.0,0.8571428571428571,0.1428571428571429,10.0,1.0,0.0,0.668421052631579
"ble because, in the case of the ASteCA membership probabilities,",0.0,0.859375,0.140625,10.0,1.0,0.0,0.6631578947368422
we also include the performance of the center of the cluster and,0.0,0.828125,0.171875,12.0,1.0,0.0,0.6631578947368422
"radius estimation methods. If any of these fail, which is not un-",0.0,0.8307692307692308,0.16923076923076918,12.0,1.0,0.0,0.6578947368421053
common for scarcely populated clusters or those embedded in,0.0,0.864406779661017,0.13559322033898302,9.0,1.0,0.0,0.6894736842105262
"fields with large amounts of contamination, then the Bayesian",0.0,0.8688524590163934,0.1311475409836066,9.0,1.0,0.0,0.6789473684210526
membership estimation method in ASteCA fails too. This fact,0.0,0.864406779661017,0.13559322033898302,9.0,1.0,0.0,0.6894736842105262
"notwithstanding, this is another great result that demonstrates the",0.0,0.8805970149253731,0.11940298507462688,9.0,1.0,0.0,0.6473684210526316
capabilities of pyUPMASK.,0.0,0.92,0.07999999999999996,3.0,1.0,0.0,0.868421052631579
"                                                                                                           Article number, page 13 of 14",107.0,0.17647058823529413,0.8235294117647058,6.0,1.0,0.5631578947368421,0.28421052631578947
avr_spaces,3.239130434782609,1.0,0.0,1.0,1.0,0.01704805491990847,0.9473684210526316
                                                A&A proofs: manuscript no. pera_etal,48.0,0.38095238095238093,0.6190476190476191,5.0,1.0,0.25263157894736843,0.5578947368421052
Fig. A.1. Same as Fig. 6 but showing pyUPMASK versus ASteCA.,0.0,0.8333333333333334,0.16666666666666663,11.0,1.0,0.0,0.6842105263157895
Fig. A.2. Same as Fig. 7 but showing pyUPMASK versus ASteCA.,0.0,0.8333333333333334,0.16666666666666663,11.0,1.0,0.0,0.6842105263157895
"Article number, page 14 of 14",0.0,0.8275862068965517,0.1724137931034483,6.0,1.0,0.0,0.8473684210526315
avr_spaces,9.6,1.0,0.0,1.0,1.0,0.05052631578947368,0.9473684210526316
